{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확장성과 성능\n",
    "\n",
    "이상적인 시스템은 좋은 동시성과 지연시간이 낮은 시스템이다. 이러한 시스템은 높은 성능을 갖고 수평 확장이나 수직 확장을 할 때 시스템의 부하에 더 잘 대응한다.\n",
    "\n",
    "높은 동시성을 갖지만 높은 지연시간을 갖는 시스템은 다양한 특성을 갖고 있다. 잠재적으로 시스템의 성능과 확장성은 현재의 시스템 부하, 네트워크 지연, 컴퓨팅 자원의 지리적 분포와 요청 같은 다른 요소에 매우 민감할 수 있다.\n",
    "\n",
    "낮은 동시성과 높은 지연시간을 갖는 시스템은 최악의 경우다. 이 시스템은 나쁜 성능 특성이 있어 확장이 어렵다. 아키텍트는 시스템을 수평적으로 확장할 것인지 또는 수직적으로 확장할 것인지 결정을 하기 전에 지연시간과 동시성 문제를 해결해야 한다.\n",
    "\n",
    "확장성은 항상 성능 처리향의 변화 측면에서 설명할 수 있다.\n",
    "\n",
    "## 동시성\n",
    "\n",
    "시스템의 동시성은 시스템이 작업을 순차적으로 처리하지 않고 동시에 수행할 수 있는 정도다. 보통 동시성을 갖도록 작성된 애플리케이션은 순차적이나 연속적으로 동작하게 작성된 애플리케이션에 비해 주어진 시간에 더 많은 작업을 실행할 수 있다.\n",
    "\n",
    "순차적인 애플리케이션이 동시성을 갖게 하면 애플리케이션이 주어진 시간에 CPU나 RAM 같은 기존 컴퓨팅 자원을 더 잘 활용하도록 할 수 있다. 다시 말해, 동시성은 컴퓨팅 자원 측면에서 머신 안에서 애플리케이션을 확장하는 가장 저렴한 방법이다. \n",
    "\n",
    "동시성은 다양한 기법을 통해 달성할 수 있다. 일반적인 기법은 다음과 같다.\n",
    "\n",
    "1. 멀티 스레딩: 동시성의 가장 간단한 형태는 애플리케이션이 여러 스레드에서 병렬도 작업하도록 하는 것이다. 스레드는 CPU가 수행할 수 있는 프로그래밍 명령의 가장 간단한 시퀀스다. 프로그램은 임의의 개수를 갖는 스레드로 구성될 수 있다. 그러면 프로그램은 작업을 여러 스레드로 분산해 동시에 더 많은 작업을 실행할 수 있다. 모든 스레드는 같은 프로세스에서 실행된다.\n",
    "\n",
    "2. 멀티 프로세싱: 프로그램이 돌시성을 갖도록 확장하는 다른 방법은 단일 프로세스 대신 여러 프로세스에서 실행하는 것이다. 멀티 프로세싱은 메시지 전달과 공유 메모리 측면에서 멀티 스레딩 보다 더 많은 오버헤드를 갖는다. 그러나 CPU 집약적인 계산을 많이 수행하는 프로그램에서는 멀티 스레드보다 멀티 프로세스에서 더 많은 혜택을 얻을 수 있다.\n",
    "\n",
    "3. 비동기 처리: 비동기 처리 기법에서 작업은 시간 측면의 특정 작업 순서와 상관없이 비동기적으로 수행된다. 비동기 처리는 작업 대기열에서 작업을 선택하고 나중에 실행하기 위해 작업을 스케줄링한다. 콜백 함수나 특별한 future 객체를 통해 수신하기도 하며 대부분 딘일 스레드에서 발생한다.\n",
    "\n",
    "다른 형태의 동시 처리 기법도 있다.\n",
    "\n",
    "파이썬은 threading 모듈을 통해 멀티 스레딩을, multiprocessing 모듈을 통해 멀티 프로세스를 지원한다. 비동기 실행 지원은 asyncio 모듈을 통해 사용할 수 있다. 스레드 및 프로세스와 비동기 실행을 결합하는 동시 처리 형태는 concurrent, futures 모듈을 통해 가능하다.\n",
    "\n",
    "### 동시성과 병렬처리\n",
    "\n",
    "동시성과 가까운 개념인 병럴처리를 간단히 살펴보자.\n",
    "\n",
    "동시성과 병렬처리는 모두 작업을 순차적으로 실행하기보단 동시에 작업을 실행하는 것이다. 동시성을 위해 두 작업이 정확히 같은 시간에 실행될 필요는 없다. 대신, 작업이 동시에 실행되도록 스케줄링돼야 한다. 반면, 병렬처리는 두 작업이 주어진 시간에 함께 실행돼야 한다.\n",
    "\n",
    "실생활의 예로 집의 두 개 외벽에 페인트칠을 한다고 해보자. 한 명의 페인트공을 고용했고 생각보다 작업이 오래 걸린다는 사실을 알게 됐다. 다음과 같은 두 가지 방법으로 문제를 해결할 수 있다.\n",
    "\n",
    "1. 다음 벽으로 전환하기 전에 페인트공에게 한 벽에 몇 번의 도장을 하도록 지시한다. 그리고 다음 벽에 똑같이 작업한다. 페인트공이 효율적으로 작업을 한다면 그는 두 벽을 동시에 작업할 것이고 주어진 시간에 두 벽 모두를 같은 완성도로 마무리할 수 있을 것이다. 이것이 동시성을 갖는 솔루션이다.\n",
    "\n",
    "2. 한 명의 페인트공을 더 고용한다. 첫 번쨰 페인트공에게 첫 번쨰 벽을, 두 번째 페인트 공에게는 두 번쨰 벽을 칠하라고 지시한다. 이것이 병렬 처리 솔루션이다.\n",
    "\n",
    "CPU는 한 시점에 하나의 스레드만 수용할 수 있기 때문에 하나의 코어를 갖는 CPU에서 바이트 코드 계산을 수행하는 두 개의 스레드는 정확하게 병렬로 계산하지 못한다. 그러나 두 스레드는 프로그래머의 관점에서 동시성을 갖는다. CPU 스케줄러가 스레드를 빠르게 전환해 스레드가 동시에 수행되는 것처럼 보이기 때문이다.\n",
    "\n",
    "그러나 멀티 코어 CPU에서 두 개의 스레드는 주어진 모든 시간에 서로 다른 코어에서 병렬로 계산을 수행할 수 있다. 이것이 진정한 병렬 처리라고 볼 수이싿.\n",
    "\n",
    "병렬적인 계산에는 컴퓨팅 자원이 최소환의 확장에 따라 선형적으로 증가하는 것이 필요하다. 동시성을 갖는 계산은 멀티 태스킹 기법을 사용해 이루어질 수 이싿. 반면, 일관처리에서 스케줄링을 통해 실행되는 작업은 기존 자우너을 더 잘 활용한다. \n",
    "\n",
    "### 파이썬에서의 동시성 - 멀티스레딩\n",
    "\n",
    "멀티스레딩을 통해 파이썬에서의 도잇 처리 기법을 알아보자.\n",
    "\n",
    "threading 모듈은 다중 스레드 프로그래밍을 지원한다. threading 모듈은 스레드의 실행을 캡슐화하는 Thread 클래스를 노출시킨다. 이와 더불어 다음과 같은 기본 요소들도 노출시킨다.\n",
    "\n",
    "1. Lock 객체는 공유 리소스를 동기화한다. 안전환 접근에 유용하며 RLock과 유사하다.\n",
    "2. Condition 객체는 임의의 조건을 기다리는 동안 스레드를 동기화시키는 데 유용하다.\n",
    "3. Event 객체는 스레드 사이의 기본적인 시그널링 메커니즘을 제공한다.\n",
    "4. Semaphore 객체를 통해 제한된 자원에 동기화된 접근을 할 수 있다.\n",
    "5. Barrier 객체는 고정된 스레드의 집합이 서로 대기하고, 특정 상태를 동기화하며 작업을 진행할 수 있게 한다.\n",
    "\n",
    "파이썬의 Thread 객체는 스레드에 안전한 생상자/소비자 워크플로우를 구현하기 위해 queue 모듈의 동기화된 Queue 클래스와 결합할 수 있다.\n",
    "\n",
    "### 썸네일 생성기\n",
    "\n",
    "이미지 URL들의 썸네일 생성에 사용하는 프로그램 예제를 통해 파이썬의 멀티스레딩을 살펴본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import urllib.request\n",
    "\n",
    "def thumbnail_image(url, size=(64, 64), format='.png'):\n",
    "    \"\"\" Save thumbnail of an image URL \"\"\"\n",
    "    \n",
    "    im = Image.open(urllib.request.urlopen(url))\n",
    "    pieces = url.split('/')\n",
    "    filename = ''.join((pieces[-2],'_',pieces[-1].split('.')[0],'_thumb',format))\n",
    "    im.thumbnail(size, Image.ANTIALIAS)\n",
    "    im.save(filename)\n",
    "    print(\"Saved\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 코드는 단일 URL에 대해서는 매우 잘 동작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 000_fff_thumb.png\n",
      "Saved fff_00_thumb.png\n",
      "Saved ccc_aaa_thumb.png\n",
      "Saved ddd_eee_thumb.png\n",
      "Saved 111_222_thumb.png\n"
     ]
    }
   ],
   "source": [
    "imgs_urls = [\n",
    "    \"https://dummyimage.com/256x256/000/fff.jpg\",\n",
    "    \"https://dummyimage.com/320x240/fff/00.jpg\",\n",
    "    \"https://dummyimage.com/640x480/ccc/aaa.jpg\",\n",
    "    \"https://dummyimage.com/128x128/ddd/eee.jpg\",\n",
    "    \"https://dummyimage.com/720x720/111/222.jpg\"]\n",
    "for url in imgs_urls:\n",
    "    thumbnail_image(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time python3 thumbnail_converter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동시에 변환을 수행할 수 있도록 멀티스레드 프로그램으로 확장해 보자. 다음은 각 변환 작업이 자체적인 스레드로 수행되도록 다시 작성된 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "for url in imgs_urls:\n",
    "    t= threading.Thread(target=thumbnail_image, args=(url,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로그램은 스레드 수에 따라 선형적으로 확장됐다. 확장성을 높이기 위해 함수 자체는 아무것도 바꾸지 않았다는 사실에 유념하자.\n",
    "\n",
    "### 썸네일 생성기 - 생산자/소비자 아키텍처\n",
    "\n",
    "현실에서는 고정된 URL 리스트 처리보다 URL 생성자를 통해 생성되는 URL 데이터의 처리가 더 일반적이다. 이런 데이터는 DB, CSV, TCP 소켓에서 가져올 수 있다.\n",
    "\n",
    "이런 시나리어오세는 URL마다 스레드를 생성하는 것은 엄청난 자원 낭비가 될 수 있다.\n",
    "\n",
    "시스템에서 스레드를 생성하기 위해서는 약간의 오버헤드가 발생한다. 생성한 스레드를 재사용하기 위한 방법이 필요하다.\n",
    "\n",
    "데이터를 사용하거나 처리하는 또 다른 스레드 세트를 생성하는, 특정 스레드 세트를 포함하는 시스템에서는 생산자/소비자 모델이 이상적이다. 시스템은 다음과 같은 기능을 갖는다.\n",
    "\n",
    "1. 생산자는 데이터 생성에 특화된 워커 클래스다. 이들은 특정 소스 데이터를 수신하거나 자체적으로 데이터를 생성할 수 있다.\n",
    "\n",
    "2. 생산자는 공유된 동기화 큐에 데이터를 추가한다. 파이썬에서 동기화 큐는 queue 모듈의 Queue 클래스에 의해 제공된다.\n",
    "\n",
    "3. 특화된 다른 워커 클래스 세트인 소비자는 큐에서 대기하는 데이터를 가져온다. 소비자는 데이터를 언더 오면 데이터를 처리하고 결과를 산출한다.\n",
    "\n",
    "4. 생산자가 데이터의 생성을 중단하고 소비자에게 데이터를 주지 않으면 프로그램이 종요된다. 다임 아웃, 폴링, 포이즌 필 같은 기법이 사용될 수 있다. 이런 일이 발생하면 모든 스레드가 종료되고 프로그램이 끝난다.\n",
    "\n",
    "소비자/생산자 아키텍처로 써메닝 생성기를 다시 작성했다. 다시 작성된 코드는 다음과 같다. 코드에서 세부 사항을 다루고 있어 크랠스를 하나씩 살펴볼 것이다.\n",
    "\n",
    "먼저 import 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 생산자 클래스를 위한 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailURL_Generator(threading.Thread):\n",
    "    \"\"\" Worker class that generates image URLs \"\"\"\n",
    "    \n",
    "    def __init__(self, queue, sleep_time=1,):\n",
    "        self.sleep_time = sleep_time\n",
    "        self.queue = queue\n",
    "        self.flag = True\n",
    "        self._sizes = (240, 320, 360, 480, 600, 720)\n",
    "        self.url_template = \"https://dummyimage.com/%s/%s/%s.jpg\"\n",
    "        threading.Thread.__init__(self, name=\"producer\")\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Producer\"\n",
    "    \n",
    "    def get_size(self):\n",
    "        return \"%d%d\" %(random.choice(self._sizes), random.choice(self._sizes))\n",
    "    \n",
    "    def get_color(self):\n",
    "        return ''.join(random.sample(string.hexdigits[:-6], 3))\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        while self.flag:\n",
    "            url = self.url_template %(self.get_size(), self.get_color(), self.get_color())\n",
    "        print(self, \"Put\", url)\n",
    "        self.queue.put(url)\n",
    "        time.sleep(self.sleep_time)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생산자 클래스를 분석한 내용이다.\n",
    "\n",
    "1. 클래스 이릉은 Thumbnail_Generator이다. Thumbnail_Generator 클래스는 다양한 크기의 전경색과 배경색을 갖는 URL을 생성한다. 클래스는 threading.Thread를 상속받는다.\n",
    "\n",
    "2. 생산자 클래스는 루프로 들어가서 임의의 이미지 URL을 생성하고 URL을 공유큐로 푸시하는 run 메소드를 갖고 있다. 스레드는 매번 sleep_time 파라미터에 구성된 대로 고정된 시간 동안 휴면 상태를 유지한다.\n",
    "\n",
    "3. 내부 플래그를 False로 설정해 루프를 중단시키고 스레드 처리를 완료하는 stop 메소드가 노출돼 있다. stop 메소드는 다른 스레드, 주 메인 스레드가 외부에서 호출할 수 있다.\n",
    "\n",
    "URL 소비자 클래스다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailURL_Consumer(threading.Thread):\n",
    "    \"\"\" Worker class that consumes URLs and generates thumbnails \"\"\"\n",
    "    \n",
    "    def __init__(self, queue):\n",
    "        self.queue = queue\n",
    "        self.flag = True\n",
    "        threading.Thread.__init__(self, name=\"consumer\")\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Consumer\"\n",
    "    \n",
    "    def thumbnail_image(self, url, size=(64, 64), format = \".png\"):\n",
    "        \"\"\" Save image thumbnails, given a URL \"\"\"\n",
    "        \n",
    "        im = Image.open(urllib.request.urlopen(url))\n",
    "        filename = url.split(\"/\")[-1].split(\".\")[0] + \"thumb\" + format\n",
    "        im.thumbnail(size, Image.ANTIALIAS)\n",
    "        im.save(filename)\n",
    "        print(self, \"Saved\", filename)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\" Main thread function \"\"\"\n",
    "        while self.flag:\n",
    "            url = self.queue.get()\n",
    "            print(self, \"Got\", url)\n",
    "            self.thumbnail_image(url)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소비자 클래스\n",
    "\n",
    "1. 클래스 이름은 ThumbnailURL_Consumer으로 큐에서 URL을 소비하고 URL 썸네일 이미지를 만든다.\n",
    "\n",
    "2. run 메소드는 루프에서 수행되며 큐에서 URL을 가져와 thumbnail_image 메소드에 전달해 썸네일을 변환한다.\n",
    "\n",
    "3. stop 메소드는 루프에서 매번 중지 플래그를 점검하고 플래그가 해제되면 끝나는 것과 매우 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue(maxsize=200)\n",
    "producers, consumers = [], []\n",
    "\n",
    "for i in range(2):\n",
    "    t = ThumbnailURL_Generator(q)\n",
    "    producers.append(t)\n",
    "    t.start()\n",
    "\n",
    "for i in range(2):\n",
    "    t = ThumbnailURL_Generator(q)\n",
    "    producers.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 썸네일 생산자/소비자 프로그램에서는 생산자는 임의의 데이터를 계속 생성하기 때문에 소비자는 끝없이 데이터를 소비할 것이다. 적절한 종료 조건을 갖고있지 않다.\n",
    "\n",
    "따라서 프로그램은 네트워크 요청이 거부되거나 타임 아웃이 발생할 떄까지 계속될 것이다. 아니면 썸네일 때문에 컴퓨터를 실행하기 위한 충분한 디스크 공간이 부족할 때까지 프로그램은 계속 실행될 것이다.\n",
    "\n",
    "현실의 문제를 처리하는 프로그램은 많은 외부의 제약 조건들 때문에 예측 가능한 임의의 방법으로 끝나야 한다.\n",
    "\n",
    "* 특정 최대시간 동안 소비자가 데이터를 기다릴 떄 타임 아웃이 바랭할 수 있는데, 그 시간 동안 이용 가능한 데이터가 없다면 종료한다. 예를 들어 큐의 get 메소드에서 타임아웃으로 설정될 수 있다.\n",
    "\n",
    "* 다른 기술로는 특정 개수의 자원이 소비되거나 생성된 후의 프로그램이 종료 시그널이 될 수 있다. 이 프로그램에서는 생성된 썸네일의 고정된 제한 개수가 될 수 있다.\n",
    "\n",
    "자금 및 세마포어 같은 스레드 동기화 기본 요소를 사용해 자원 제한을 강제화하는 방법을 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread 서브클래스 안에 재정의된 메소드가 실행돼도 start 메소드를 사용해 스레드를 시작하는 것을 관찰했는데, 부모 Thread start 메소드가 일부 상태를 설정한 다음 내부적으로 run 메소드를 호출하기 때문이다. 이 방법이 스레드의 run 메소드를 호출하는 올바른 방법이다. 스레드의 run 메소드는 절대로 직접 호출하면 안 된다.\n",
    "\n",
    "### 썸네일 생성기 - 잠금을 사용하는 자원 제한\n",
    "\n",
    "프로그램은 디스크 공간이나 네트워크 대역폭이 모두 소모될 떄까지 끝없이 실행되는 문제가 있다.\n",
    "\n",
    "프로그램을 끝내기 위해 생성된 이미지 수를 제한하는 카운터를 구현한다. 카운터를 만들기 위해 동기화 기본 요소인 잠금(Lock) 기능을 사용해 프로그램을 수정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사 코드는 다음과 같다.\n",
    "try:\n",
    "    lock.acquire()\n",
    "    # Do some modification on a shared, mutable resource\n",
    "finally:\n",
    "    lock.relese()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lock 객체는 with 문장과 함께 컨텍스트 관리자를 지원한다. 보통 다음과 같이 작성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Lock:\n",
    "    mutable_object.modify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행할 떄마다 고정 개수의 이미지를 구현하려면 코드에 카운터를 추가해야 한다. 그러나 여러 스레드가 이 카운터를 확인하고 증가시켜야 하므로 Lock 객체를 통한 동기화가 필요하다.\n",
    "\n",
    "잠금을 사용하는 리소스 카운터 클래스의 첫 번쨰 구현 코드는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailImageSaver(object):\n",
    "    \"\"\" Class which saves URLs to thumbnail images and keeps a counter \"\"\"\n",
    "    \n",
    "    def __init__(self, limit=10):\n",
    "        self.limit = limit\n",
    "        self.lock = threading.Lock()\n",
    "        self.counter = {}\n",
    "        \n",
    "    def thumbnail_image(self, url, size=(64, 64), format = \".png\"):\n",
    "        \"\"\" Save image thumbnails, given a URL \"\"\"\n",
    "        \n",
    "        im = Image.open(urllib.request.urlopen(url))\n",
    "        filename = url.split(\"/\")[-1].split(\".\")[0] + \"thumb\" + format\n",
    "        im.thumbnail(size, Image.ANTIALIAS)\n",
    "        im.save(filename)\n",
    "        print(self, \"Saved\", filename)\n",
    "        self.counter[filename] = 1\n",
    "        return True\n",
    "    \n",
    "    def save(self, url):\n",
    "        with self.lock:\n",
    "            if len(self.counter) >= self.limit:\n",
    "                return False\n",
    "            self.thumbnail_image(url)\n",
    "            print(\"Count => \", len(self.counter))\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞과 같이 바꾸면 소비자 클래스도 변경해야 한다. 다음은 이미지 추적에 필요한 추가 카운터를 수용하기 위해 변경한 소비자 클래스다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "class ThumbnailURL_Consumer(threading.Thread):\n",
    "    \"\"\" Worker class that consumes URLs and generates thumbnails \"\"\"\n",
    "    \n",
    "    def __init__(self, queue, saver):\n",
    "        self.queue = queue\n",
    "        self.flag = True\n",
    "        self.count = 0\n",
    "        self.saver = saver\n",
    "        self._id = uuid.uuid4().hex\n",
    "        threading.Thread.__init__(self, name=\"Consumer-\" + self._id)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Consumer-\" + self._id\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\" Main thread function \"\"\"\n",
    "        while self.flag:\n",
    "            url = self.queue.get()\n",
    "            print(self,'Got',url)\n",
    "            self.count += 1\n",
    "            if not self.saver.save(url):\n",
    "               # Limit reached, break out\n",
    "               print(self, 'Set limit reached, quitting')\n",
    "               break\n",
    "    \n",
    "    def stop(self):\n",
    "        self.flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ThumbnailImageSaver는 Thread가 아니며 Thread가 될 수 없다.\n",
    "2. ThumbnailImageSaver 클래스는 초기화 메소드에서 잠금 객체와 카운터 딕셔너리를 초기화한다. 잠금은 스레드에 의한 카운터 접근을 동기화하기 위한 것이다. 또한 저장해야 하는 이미지 개수와 같은 limit 파라미터도 허용한다.\n",
    "3. thumbnail_image 메소드는 소비자 클래스에서 ThumbnailImageSaver 클래스로 이동한다. 이것은 잠금을 사용해 동기화된 컨텍스트의 save 메소드에서 호출된다.\n",
    "4. save 메소드는 먼저 카운터가 설정된 한계를 초과했는지 확인한다. 한계를 초과하면 메소드는 False를 반환한다. 그렇지 않으면 이미지는 thumbnail_image 메소드 호출과 함께 저장된다. 이미지 파일 이름이 카운터에 추가되고 카운터가 증가한다.\n",
    "\n",
    "수정된 ThumbnailURL_Consumer 클래스를 알아보자.\n",
    "1. ThumbnailURL_Consumer 클래스의 이니셜라이저는 saver 인수로 ThumbnailImageSaver의 인스턴스를 허용할 수 있도록 수정됐다. \n",
    "2. thumbnail_image 메소드는 새로운 클래스로 이동했기 때문에 더 이상 ThumbnailURL_Consumer에 존재하지 않는다. \n",
    "3. run 메소드가 훨씬 더 단순해졌다. False가 반환되면 한계치에 도달했음을 의미하여 루프가 종료되고 소비자 스레드가 종료된다.\n",
    "4. 스레드마다 uuid 모듈을 사용해 이니셜라이저에서 설정되는 고유한 ID를 반환하도록 \\__str__ 메소드로 수정됐는데 이는 스레드를 디버깅할 때 도움이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "q = Queue(maxsize=1000)\n",
    "saver = ThumbnailImageSaver(limit=50)\n",
    "\n",
    "producer, consumer = [], []\n",
    "for i in range(3):\n",
    "    t = ThumbnailURL_Generator(q)\n",
    "    producer.append(t)\n",
    "    t.start()\n",
    "\n",
    "for i in range(5):\n",
    "    t = ThumbnailURL_Consumer(q, saver)\n",
    "    consumer.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in consumer:\n",
    "    t.join()\n",
    "    print(\"Joined\", t, flush=True)\n",
    "\n",
    "while not q.empty():\n",
    "    item=q.get()\n",
    "for t in producer:\n",
    "    t.stop()\n",
    "    print(\"Stopped\", t, flush=True)\n",
    "\n",
    "print(\"Total number of PNG images\", len(glob.glob(\"*.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 새로운 ThumbnailImageSaver 클래스의 인스턴스 생성하고 이들이 생성될 때 소비자 스레드로 전달한다.\n",
    "2. 먼저 소비자를 기다린다. 메인 스레드는 stop을 호출하지 안히만 소비자 스레드에 join을 호출한다. 소비자가 한계에 도달하면 자동으로 종료하기 때문이다.\n",
    "3. 생산자가 종료하기 위한 조건이 없어 계속 동작하기 때문에 명시적으로 소비자가 동료된 후 생산하자를 종료한다.\n",
    "\n",
    "### 썸네일 생성기 - 세마포어를 사용하는 리소스 제한\n",
    "\n",
    "잠근은 동기화 제약사항을 구현하는 유일한 방법이 아니며, 시스템에서 사용/생성되는 자원의 제한 기능처럼 이들의 상위에서 로직을 작성한다.\n",
    "\n",
    "컴퓨터 과학에서 세마포어는 오래된 도익화 기본 요소 중 하나로 이러한 유즈케이스에 이상적이다.\n",
    "\n",
    "세마포어는 0보다 큰 값으로 초기화된다.\n",
    "\n",
    "1. 스레드가 양의 내부 값을 갖는 세마포어에 aqcuire를 호출하면 값은 1씩 감소한다.\n",
    "2. 다른 스레드가 세마포어에 release를 호출하면 값은 1씩 증가한다.\n",
    "3. 갑이 0에 도달하면 세마포어에 관한 모든 스레드의 release를 호출하는 다른 스레드에 의해 깨어날 때까지 acquire 호출이 차단된다.\n",
    "\n",
    "세마포어를 사용해 썸네일 생성기 프로그램의 자원 제한을 위한 또 다른 클래스를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailImageSemaSaver(object):\n",
    "    def __init__(self, limit=10):\n",
    "        self.limit = limit\n",
    "        self.counter = threading.BoundedSemaphore(value=limit)\n",
    "        self.count = 0 \n",
    "    \n",
    "    def acquire(self):\n",
    "        return self.counter.acquire(blocking=False)\n",
    "    \n",
    "    def release(self):\n",
    "        return self.counter.release()\n",
    "\n",
    "    def thumbnail_image(self, url, size=(64, 64), format=\".png\"):\n",
    "        im=Image.open(urllib.request.urlopen(url))\n",
    "        pieces = url.split(\"/\")\n",
    "        filename = ''.join((pieces[-2], \"_\", pieces[-1].split(\".\"[0], format)))\n",
    "        try:\n",
    "            im.thumbnail(size, Image.ANTIALIAS)\n",
    "            im.save(filename)\n",
    "            self.count += 1\n",
    "        except Exception as e:\n",
    "            self.release()\n",
    "        return True\n",
    "    \n",
    "    def save(self, url):\n",
    "        if self.acquire():\n",
    "            self.thumbnail_image(url)\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. acquire와 release 메소드는 세마포어의 같은 메소드에 대한 단순 래퍼다.\n",
    "2. 초기화 메소드의 제한 값과 같은 값으로 세마포어를 초기화한다.\n",
    "3. save 메소드에서 acqurie 메소드를 호출한다. 세마포어의 한계치에 도달하면 False가 반환된다. 그렇지 않으면 이미지를 저장하고 True를 반환한다. False가 반환되면 스레드 호출이 종료된다. \n",
    "\n",
    "### 리소스 제한 - 세마포어 VS 잠금\n",
    "\n",
    "차이점 \n",
    "\n",
    "1. 잠금을 사용하는 버전은 데이터의 불일치를 확인하기 위해 리소스를 수정하는 모든 코드를 보호한다. 카운터를 확인하고 썸네일을 저장한 후 카운터를 증가한다.\n",
    "2. 세마포어 버전은 카운터가 제한 값보다 작으면 스레드가 통과할 수 있고, 제한에 도다랄 때만 닫히는 문과 유사하게 구현된다. 세마포어 버전은 썸네일 저장 기능을 호출해 스레드에 대한 상호배제를 하지 않는다.\n",
    "\n",
    "따라서 세마포어 버전이 잠금을 사용하는 버전보다 더 빠르다.\n",
    "\n",
    "### 썸네일 생성기 - 조건을 사용하는 URL 비율 컨트롤러\n",
    "\n",
    "스레딩의 중요한 동기화 기본 요소인 Condition 객체를 간단히 살펴본다.\n",
    "\n",
    "Condition 객체를 사용하는 예제를 작성하고, URL 생성 비율을 관리하기 위한 썸네일 생성기의 조절기를 구현한다.\n",
    "\n",
    "실제 생산자/소비자 시스템에서는 데이터 생성과 소비 비율에 따라 다음과 같은 세 가지 상황이 생길 수 있다.\n",
    "\n",
    "1. 소비자가 소비하는 것보다 더 빠른 속도로 생산자가 데이터를 생산한다. 생산자에 의한 초과 데이터는 큐에 누적될 수 있으며, 큐가 더 많은 메모리와 CPU 사용량을 소비하게 만들어 프로그램이 느려지는 원인이 된다.\n",
    "\n",
    "2. 소비자가 생산자보다 더 빠른 비율로 데이터를 소비한다. 이것은 소비자가 항상 큐의 데이터를 기다리는 원인이 된다. 생산자가 너무 지체하지 않는 한 그 자체로는 문제가 아니지만 최악의 경우, 시스템의 절반 즉 소비자를 유휴 상태에 있게 한다.\n",
    "\n",
    "3. 생산자와 소비자 모두 큐 크기를 제한 범위 안으로 유지하면서 거의 같은 속도로 동작한다.\n",
    "\n",
    "해결방법\n",
    "\n",
    "1. 고정된 크기를 갖는 큐\n",
    "\n",
    "2. 타임아웃에 더해 다른 책임을 워케에게 제공한다: 큐를 차단된 상태로 유지하기보다는 생산자 또는 소비자가 큐에서 데이터를 기다리기 위한 타임아웃을 사용할 수 있다. 시간이 초과하면 이들은 큐로 돌아가 대기하기 전에 휴지 상태가 되거나 다른 책임에 관련된 작업을 수행할 수 있다.\n",
    "\n",
    "3. 동적으로 워커의 수를 설정: 수요에 따라 워쿼 풀 크기가 자동으로 증가하거나 감소되는 방법이다. \n",
    "\n",
    "4. 데이터 생성 비율을 조정한다: 정적 또는 동적으로 생산자의 데이터 생성 비율을 조정한다. \n",
    "\n",
    "URL의 생산 속도를 고정된 제한 값으로 제한하기 위해 Condition 객체를 사용해 마지막 방법으로 구현한다.\n",
    "\n",
    "Condition 객체는 정교한 동기화 기본 요소로 명시적으로 내장된 잠금 기능을 갖고 있다.\n",
    "Condition 객체는 임의의 조건이 True가 될 때까지 기다릴 수 있다. 스레드가 조건에 대해 wait를 호출하는 순간, 내부 잠금은 해제되지만 스레드 자체는 차단된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "def some_condition_is_satistied():\n",
    "    return True\n",
    "# In thread #1\n",
    "cond = threading.Condition()\n",
    "with cond:\n",
    "    while not some_condition_is_satistied():\n",
    "        cond.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 다른 스레드가 조건을 True로 설정해서 선행 스레드를 깨울 수 있다. 그 다음, Condition 객체에 notify나 notify_all을 호출한다. 이 시점에 앞서 차단된 스레드가 깨어나 작업을 계속 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In thread #2\n",
    "cond = threading.Condition()\n",
    "with cond:\n",
    "    while not some_condition_is_satistied():\n",
    "        cond.notify_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition 객체를 사용해 URL 생성 속도를 제어하는 새로운 클래스인 ThumbnailURLController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailURLController(threading.Thread):\n",
    "    def __init__(self, rate_limit=0, nthread=0):\n",
    "        # Configured rate limit\n",
    "        self.rate_limit = rate_limit\n",
    "        # Number of producer threads\n",
    "        self.nthreads = nthread\n",
    "        self.count = 0\n",
    "        self.start_t = time.time()\n",
    "        self.flag = True\n",
    "        self.cond = threading.Condition()\n",
    "        threading.Thread.__init__(self)\n",
    "    \n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "    \n",
    "    def calc_rate(self):\n",
    "        rate = 60.0*self.count/(time.time() - self.start_t)\n",
    "        return rate\n",
    "    \n",
    "    def run(self):\n",
    "        while self.flag:\n",
    "            rate = self.calc_rate()\n",
    "            if rate<= self.rate_limit:\n",
    "                with self.cond:\n",
    "                    self.cond.notify_all()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.flag = False\n",
    "    \n",
    "    def throttle(self, thread):\n",
    "        rate = self.calc_rate()\n",
    "        diff = abs(rate - self.rate_limit)\n",
    "        sleep_diff = diff/(self.nthreads*60.0)\n",
    "        \n",
    "        if rate > self.rate_limit:\n",
    "            thread.sleep_time += sleep_diff\n",
    "            with self.cond:\n",
    "                while self.calc_rate() > self.rate_limit:\n",
    "                    self.cond.wait()\n",
    "                    \n",
    "        elif rate < self.rate_limit:\n",
    "            sleep_time = thread.sleep_time\n",
    "            sleep_time -= sleep_diff\n",
    "            thread.sleep_time = max(0, sleep_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ThumbnailURLController 클래스는 Thread 인스턴스이므로 자체적인 실행 스레드에서 실행된다.\n",
    "\n",
    "2. ThumbnailURLController 클래스는 카운터를 유지하고 타임스탬프를 사용해 URL 생성 속도를 계산하는 calc_rate 메소드가 있다.\n",
    "\n",
    "3. run 메소드에서 속도가 확인된다. 설정된 한계보다 아래면 Condition 객체는 대기 중인 모든 스레드에 통보한다.\n",
    "\n",
    "4. 가장 중요한 방법은 throttle 메소드의 구현이다. calc_rate를 통해 구한 현재 속도를 이용하며 이를 생산자의 휴면 시간을 조절하고 조정하는 데 사용한다.\n",
    "    \n",
    "    1. 속도가 설정된 한계보다 크면 속도가 내려갈 떄까지 Condition 객체에 스레드 호출을 대기시키는 원인이 된다. 추가적인 휴면 시간을 계산해 필요한 수준으로 속도를 조절하기 위해 스레드가 루프에서 휴면 상태여야 한다.\n",
    "    2. 속도가 구성된 한계보다 낮으면 스레드는 더 빠르게 작업하고 더 많은 데이터를 생성해야 한다. 따라서 생산자와 소비자의 휴면 시간의 차이를 계산하고 이를 따라 휴면 한계를 낮춘다.\n",
    "    \n",
    "다음은 변경사항을 통합할 생산자 클래스의 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailURL_Generator(threading.Thread):\n",
    "    \n",
    "    def __init__(self, queue, controller=None, sleep_time=1):\n",
    "        self.sleep_time = sleep_time\n",
    "        self.queue = queue\n",
    "        self.flag = True\n",
    "        self._sizes = (240, 320, 360, 480, 600, 720)\n",
    "        self.url_template = \"https://dummyimage/com/%s/%s/%s.jpg\"\n",
    "        self.controller = controller\n",
    "        self._id = uuid.uuid4().hex\n",
    "        threading.Thread.__init__(self, name=\"Producer-\" + self._id)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Producer-\" + self._id\n",
    "    \n",
    "    def get_size(self):\n",
    "        return \"%d%d\" %(random.choice(self._sizes),\n",
    "                        random.choice(self._sizes))\n",
    "    \n",
    "    def get_color(self):\n",
    "        return ''.join(random.sample(string.hexidigis[:-6], 3))\n",
    "\n",
    "    def run(self):\n",
    "        while self.flag:\n",
    "            url = self.url_template %(self.get_size(),\n",
    "                                      self.get_color(),\n",
    "                                      self.get_color())\n",
    "            \n",
    "            self.queue.put(url)\n",
    "            self.controller.increment()\n",
    "\n",
    "            if self.controller.count > 5:\n",
    "                self.controller.throttle(self)\n",
    "\n",
    "            time.sleep(self.sleep_time)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이제 클래스는 이니셜라이저에서 추가적인 컨트롤러 객체를 허용한다. 이것은 이전에 주어진 컨트롤러 클래스의 인스턴스다.\n",
    "2. URL을 입력한 후 컨트롤러의 카운터를 증가시킨다. 카운터가 최소 한계치에 도달하면 컨트롤러에 대해 throttle를 호출하고 자신을 인수로 전달한다.\n",
    "\n",
    "호출 코드도 변경이 필요하다. 수정된 코드는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue(maxsize=2000)\n",
    "controller = ThumbnailURLController(rate_limit=50, nthread=3)\n",
    "saver = ThumbnailImageSemaSaver(limit=200)\n",
    "\n",
    "controller.start()\n",
    "\n",
    "producer, consumers = [], []\n",
    "for i in range(3):\n",
    "    t = ThumbnailURL_Generator(q, controller)\n",
    "    producer.append(t)\n",
    "    t.start()\n",
    "    \n",
    "for i in range(5):\n",
    "    t = ThumbnailURL_Consumer(q, saver)\n",
    "    consumers.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in consumers:\n",
    "    t.join()\n",
    "\n",
    "while not q.empty():\n",
    "    item = q.get()\n",
    "controller.stop()\n",
    "\n",
    "for r in producer:\n",
    "    t.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변경한 내용 다음과 같다.\n",
    "\n",
    "1. 생성해야 하는 정확한 생산자 개수와 함께 컨트롤러 객체가 생성됐다. 스레드 마다 정확한 휴먼 시간을 계산해야 할 때 도움이 된다.\n",
    "2. 생산자 스레드 자체는 이니셜라이저에서 컨트롤러의 인스턴스로 전달된다.\n",
    "3. 컨트롤러는 다른 모든 스레드보다 먼저 스레드로 시작된다.\n",
    "\n",
    "분당 50개 이미지 생성 비율로 200개의 이미지를 갖도록 구성된 프로그램의 실행 결과다. 실댕되는 프로그램의 출력 이미지 두 개를 볼 수 있다. 하나는 프로그램의 시작 부분에, 하나는 끝 부분에 나타난다.\n",
    "\n",
    "프로그램이 시작하면 처음 속도가 빠르게 때문에 부분은 곧바로 속도가 느려지면서 거의 중단 상태가 된다. 여기서 일어나는 일은 생산자가 throttle 메소드를 호출하고 속도가 빠르기 때문에 모두 Condition 객체에서 차단된다.\n",
    "\n",
    "몇 초가 지나면 더 이상 URL이 생성되지 않기 때문에 속도는 규정된 한도로 내려간다. 그러면 이것은 컨트롤러의 루프에서 감지되고 컨트롤러는 스레드에 대해 notify_all을 호출해 모든 스레드를 깨운다.\n",
    "\n",
    "스레드를 처리하는 기본 요소와 프로그램에서 동시성을 향상시키기 위해 스레드를 사용하는 방법을 알아봤다. 또한 공유된 자우너에 대한 제약과 통제를 구현하는 방법도 거의 마무리되고 있다.\n",
    "\n",
    "결론을 내리기 전에 파이썬에서 멀티스레드 프로그램이 CPU를 모두 사용하지 못하게 막는 파이썬 스레드의 한 측면인 GIL을 살펴보자.\n",
    "\n",
    "### 멀티스레딩 - 파이썬과 GIL\n",
    "\n",
    "파이썬에는 멀티스레드가 네이티브 바이트 코드를 즉시 실행하는 것을 방지하는 전역적인 잠금이 있다. 파이썬의 네이티브 쿠현인 CPython의 메모리 관리는 스레드에 안전성이 없기 때문에 잠금이 필요하다. 이러한 잠금을 Global Interpreter Lock 또는 GIL로 부른다.\n",
    "\n",
    "파이썬은 GIL 때문에 CPU에서 바이트 코드 연산을 동시에 수행할 수 없다. 따라서 다음 상황는 파이썬이 적합하지 않다.\n",
    "\n",
    "* 프로그램이 동시에 수행해야 하는 많은 바이트 코드 연산에 의존하는 경우\n",
    "* 프로그램이 단일 머신에서 여러 CPU 코어의 완전한 기능을 활용하기 위해 멀티스레드를 사용하는 경우\n",
    "\n",
    "I/O 호출과 장시간 실행되는 동작 GIL 외부에서 발생한다. 따라서 파이썬에서 멀티스레딩은 이미지 처리 같은 작업이나 어느 정도 I/O를 포함하는 경우에 효율적이다. 이때는 동시에 단일 프로세스 이상으로 확장할 수 있도록 프로그램을 확장시키는 방법이 편리한데 파이썬은 multiprocessing 모듈을 통해 이를 지원한다.\n",
    "\n",
    "### 파이썬의 동시성 처리 - 멀티 프로세싱\n",
    "\n",
    "파이썬 표준 라이브러리는 프로그래머가 스레드 대신 여러 프로세스를 사용해 동시에 확장 가능한 프로그램을 작성할 수 있도록 멀티 프로세싱 모듈을 제공한다.\n",
    "\n",
    "멀티 프로세싱은 여러 프로세스에 걸쳐 계산을 확장하기 때문에 파이썬에서 GIL이 갖는 모든 문제를 효과적으로 제거한다. 프로그램은 멀티 프로세싱 모듈을 사용해 효과적으로 여러 CPU 코어를 사용할 수 있다.\n",
    "\n",
    "멀티 프로세싱 모듈의 주요 클래스는 Process 클래스로 스레딩 모듈 Thread 클래스와 유사다. Process 클래스는 스레딩 모듈의 Thread와 거의 정확하게 대응하는 동기화 기본요소를 많이 제공한다.\n",
    "\n",
    "멀티 프로세싱 모듈에서 제공하는 Pool 객체의 사용 예제로 시작하며, Pooll 객체의 사용은 프로세스를 사용해 여러 입력을 병렬로 실행할 수 있게 된다.\n",
    "\n",
    "### 소수 검사기\n",
    "\n",
    "다음 함수는 입력 번호가 소수인지 아닌지를 판별하는 간단한 소수 검사 기능을 갖는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    for i in range(3, int(n**0.5+1), 2):\n",
    "        if n % i == 0:\n",
    "            print(n, 'is not prime')\n",
    "            return False\n",
    "\n",
    "    print(n, 'is prime')    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 소수 큐에서 숫자를 검사하기 위해 앞의 함수를 사용하는 스레드로 처리된 클래스다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class PrimeChecker(threading.Thread):\n",
    "    \"\"\" Thread class for primality checking \"\"\"\n",
    "    \n",
    "    def __init__(self, queue):\n",
    "        self.queue = queue\n",
    "        self.flag = True\n",
    "        threading.Thread.__init__(self)\n",
    "    \n",
    "    def run(self):\n",
    "        while self.flag:\n",
    "            try:\n",
    "                n = self.queue.get(timeout=1)\n",
    "                is_prime(n)\n",
    "            except Empty:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1297337, 1116281, 104395303, 472882027, 533000389]\n",
    "\n",
    "q = Queue(1000)\n",
    "\n",
    "for n in numbers:\n",
    "    q.put(n)\n",
    "\n",
    "threads = []\n",
    "for i in range(4):\n",
    "    t = PrimeChecker(q)\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트를 위해 네 개의 스레드를 사용했다. 다음 화면에서 프로그램의 동작 방법을 살펴보자.\n",
    "\n",
    "### 디스크 파일 정렬\n",
    "\n",
    "이제 멀티 프로세싱 Pool 객체를 사용하는 같은 코드가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자들을 비교하면 다음 사항을 알 수 있다.\n",
    "\n",
    "1. 실시간 즉, 프로세스 풀 버전에서 사용한 벽시계 시간은 1분 9.6초는 스레드 풀 버전의 벽 시계 시간 2분 12초보다 거의 50% 더 쩗다.\n",
    "2. 그러나 프로세스 풀 버전의 사용자 시간인 4분 22초는 스레드 풀 버전의 사용자 시간 2분 12초의 거의 두 배가 된다.\n",
    "3. 스레드 풀 버전의 실제 CPU 시간과 사용자 CPU 시간은 2분 12초로 정확히 같다. 이것은 스레드 처리 버전 CPU 코어 중 하나에서만 효과적으로 실행될 수 있다는 명백한 표시다.\n",
    "\n",
    "이것은 프로세스 풀 버전이 모든 CPU 코어를 더 잘 사용할 수 있음을 의미하며, 스레드 풀 버전의 실제 시간 대비 50%이므로 CPU 시간을 두 배 이상 사용할 수 있다.\n",
    "\n",
    "따라서 CPU 시간/실제 시간 측면에서 두 프로그램의 실제 성능 향상은 다음과 같다.\n",
    "\n",
    "1. 스레드 버전 -> 132초/123초=1\n",
    "2. 프로세스 버전 -> 262초/69.6초=3.76~=4\n",
    "\n",
    "스레드 버전에 대한 프로세스 버전의 실제 성능 비율은 다음과 같다.\n",
    "\n",
    "프로그램이 실행된 머신에는 4개의 코어가 있는 CPU가 있다. 멀티 프로세스 버전의 코드는 4개의 CPU 코어 모두를 거의 똑같이 활용할 수 있음을 분명하게 보여준다. 스레드 버전 GIL에 의해 제한되는 반면, 프로세스 버전은 제한없이 모든 코어를 자유롭게 이용할 수 있기 때문이다.\n",
    "\n",
    "다음 절에서는 디스크 기반 파일의 정렬에 관련된 더 복잡한 문제를 살펴볼 것이다.\n",
    "\n",
    "### 디스크 파일 정렬\n",
    "\n",
    "디스크에 수십 만 개의 파일이 있고, 파일마다 주어진 범위에서 고정된 임의의 정수를 포함하고 있다고 하자.\n",
    "\n",
    "모든 데이터를 메모리에 로드시키려면 엄청나게 많은 RAM이 필요하다. \n",
    "\n",
    "수백 만 개의 파일을 대상으로 간단히 계산해 보면, 각 파일이 1에서 10000 범위의 정수 100개를 포함하면 총 천만개 혹은 1억 개의 정수가 된다.\n",
    "\n",
    "전체 데이터가 한 번에 메모리에 로드되면 메모리 사용량은 800MB에 가깝게 된다. 리스트가 커질수록 메모리에서 데이터를 하나의 커다란 리스트로 정렬하는 데는 더 많은 시스템 자원이 필요하다.\n",
    "\n",
    "메모리와 동작 관점에서는 메모리 공간이 문제다.\n",
    "\n",
    "8GB RAM, 4코어 CPU를 갖는 64비트 리눅스 노트북에 테스트를 수행하면 백만 개의 숫자 테스트는 끝나지 않고 시스템이 중단된다.\n",
    "\n",
    "### 디스트 파일 정렬 - 카운터 사용\n",
    "\n",
    "데이터를 살펴보면 시간보다 공간 문제로 다룰 수 있는 측면이 더 많이 있다는 사실을 알 수 있는데, 최대 한계가 10000으로 고정된 범위에 있는 정수이기 때문이다.\n",
    "\n",
    "모든 데이터를 분리된 리스트로 로딩하고 병합하는 대신 카운터 같은 데이터 수조를 사용할 수 있다.\n",
    "\n",
    "동작 방법의 기본적인 아이디어는 다음과 같다.\n",
    "\n",
    "1. 데이터 구조를 초기화한다. 1에서 시작해 최대 항목 10,000까지 각 항목은 카운터가 0으로 초기화된다.\n",
    "\n",
    "2. 각 파일을 로드하고 데이터를 리스트로 변환한다. 리스트에서 발견된 숫자에 대해, 1단게에서 초기화된 카운터 데이터 구조에 해당하는 숫자의 카운트를 증가시킨다.\n",
    "\n",
    "3. 마지막으로 카운터를 반복해 0보다 큰 카운트를 갖는 각 숫자를 출력한 후 파일로 출력을 저장한다. 출력 결과는 정렬되어 병합된 하나의 파일이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import collections\n",
    "\n",
    "MAXINT = 100000\n",
    "\n",
    "def sort():\n",
    "    counter = collections.defaultdict(int)\n",
    "    for i in range(int(sys.argv[1])):\n",
    "        filename = 'numbers/numbers_%d.txt' %i\n",
    "        for n in open(filename):\n",
    "            counter[n] += 1\n",
    "            print('Sorting...')\n",
    "    with open('sorted_nums.txt', 'w') as fp:\n",
    "        for i in range(1, MAXINT+1):\n",
    "            count = counter.get(str(i) + '\\n', 0)\n",
    "            if count > 0:\n",
    "                fp.write((str(i)+ '\\n')*count)\n",
    "        print('Sorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디스크 파일 정렬 - 멀티 프로세싱 사용\n",
    "\n",
    "프로세스풀로 파일 경로 리스트를 분할하고, 입력 파일 처리를 한 개 프로세스 이상으로 확장하기 위한 것으로 결과로 나오는 데이터 병렬 처리에 따른 혜택을 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import time\n",
    "import collections\n",
    "from multiprocessing import Pool\n",
    "\n",
    "MAXINT = 100000\n",
    "\n",
    "def sorter(filnames):\n",
    "    counter = collections.defaultdict(int)\n",
    "    for filename in filenames:\n",
    "        for i in open(filename):\n",
    "            counter[i] += 1\n",
    "    return counter\n",
    "\n",
    "def batch_files(pool_size, limit):\n",
    "    batch_size = limit // pool_size\n",
    "    filenames = []\n",
    "    \n",
    "    for i in range(pool_size):\n",
    "        batch = []\n",
    "        for j in range(i*batch_size, (i+1)*batch_size):\n",
    "            filename = 'numbers/numbers_%d.txt' %(j)\n",
    "            batch.append(filename)\n",
    "        filenames.append(batch)\n",
    "    return filenames\n",
    "\n",
    "def sort_files(pool_size, filenames):\n",
    "    with Pool(pool_size) as pool:\n",
    "        counters = pool.map(sorter, filnames)\n",
    "        with open('sorted_nums.txt', 'w') as fp:\n",
    "            for i in range(1, MAXINT+1):\n",
    "                count = sum([x.get(str(i)+ '\\n', 0) for x in counters])\n",
    "                if count > 0:\n",
    "                    fp.write((str(i) + '\\n')*count)\n",
    "    print(\"Sorted\")\n",
    "\n",
    "# limit = int(sys.argv[1])\n",
    "# pool_size = 4\n",
    "# filenames = batch_files(pool_size, limit)\n",
    "# sort_files(pool_size, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 단일 리스트로 모든 파일을 처리하는 대신 파일 이름을 일괄 처리 작업들에 넣어 풀의 크기를 일괄처리 작업들과 똑같이 만든다.\n",
    "2. 파일 이름의 리스트를 반아 처리하고 카운트가 있는 딕셔너리로 변환하는 정렬 기능을 사용한다.\n",
    "3. 카운트는 각 정수 즉, 1부터 MAXINT 범위까지 합산되며 많은 수가 정렬된 파일로 기록된다.\n",
    "\n",
    "멀티 프로세스 버전은 단일 프로세스 버전에 비교해 성능적인 혜택을 많이 제공하지 않는다. 예제에서는 많은 계산이 이루어지지 않으며 병목 현상이 디스크나 파일 입출력인 경우로, 멀티 프로세싱에 따른 확장이 그다지 효과가 없는 상황을 보여준다\n",
    "\n",
    "## 멀티스레딩 VS 멀티프로세싱\n",
    "\n",
    "다음의 경우 멀티스레딩이 좋다.\n",
    "\n",
    "1. 프로그램이 많은 공유 상태 특히, 가변적인 상태를 유지해야 할 때, 리스트, 딕셔너리 같인 파이썬에 있는 많은 표준 데이터 구조들은 스레드에 안전하다. 따라서 프로세스를 사용하는 것보다 스레드를 사용해 가변적인 공유 상태를 유지하면 비용이 훨씬 더 적게 든다.\n",
    "\n",
    "2. 프로그램이 메모리 사용량을 낮게 유지해야 할 때\n",
    "\n",
    "3. 프로그램이 I/O 수행에 많은 시간을 쓸 때, GIL은 I/O를 수행하는 스레드에 의해 해제되므로 스레드가 I/O를 수행시간에 영향을 주지 않는다.\n",
    "\n",
    "4. 프로그램이 여러 프로세스에 걸쳐 확장할 수 있는 많은 양의 데이터 병렬 작업을 하지 않을 때\n",
    "\n",
    "다음은 멀티 프로세스가 유용하다.\n",
    "\n",
    "1. 프로그램이 바이트 코드 연산, 수치 처리, 대규모 입력 등 합리적인 많은 양의 CPU 제약을 갖는 컴퓨팅을 수행할 때\n",
    "\n",
    "2. 프로그램이 데이터 덩어리로 동시처리될 수 있는 입력응ㄹ 갖고 결과가 나중에 결합될 수 있을 때, 즉 병렬 계산에 적합할 때\n",
    "\n",
    "3. 프로그램이 메모리 사용량에 아무런 제한도 없고 멀티코어 CPU와 충분히 많은 RAM을 갖는 최신 기계를 사용할 때\n",
    "\n",
    "4. 프로세스 사이에 동기화가 필요한 가변적인 공유 상태가 적을 때, 도익화는 시스템을 느려지게 만들 수 있으며 멀티 프로세스에서 얻는 이점을 상쇄할 수 있다.\n",
    "\n",
    "5. 프로그램이 I/O에 많이 의존하지 않을 때\n",
    "\n",
    "### 파이썬에서의 동시성 - 비동기 실행\n",
    "\n",
    "비동기 프로그래밍이나 비동기 I/O를 사용하는 방법도 있다.\n",
    "\n",
    "비동기 실행 모델에서 태스크는 인터리브 방식으로 태스크를 실행하는 스케줄러에 의해 태스크 큐에서 실행을 위해 선택된다. 여기에는 태스크가 특정 순서로 실행된다는 보장이 없다. 태스크의 실행 순서는 태스크가 큐에서 다른 태스크에게 얼마나 많은 처리시간을 양보하는가에 따라 달라진다. 다르게 표현하면 비동기 실행은 협력적인 멀티 태스킹을 통해 이루어진다.\n",
    "\n",
    "비동기 실행은 보통 단일 스레드에서 발생한다. 진정한 데이터 병렬 처리나 병렬 실행이 발생하지 않을 수도 있음을 의미하는 대신, 모델은 병렬 처리와 유사한 모습을 제공한다.\n",
    "\n",
    "비동기 시스템은 순서대로 실행되지 않기 때문에 함수의 실행 결과를 호출자에게 반환하는 방법이 필요하다. 이것은 결과가 준비되거나 결과를 받는 futures라고 하는 특별한 객체를 사용할 때 호출돼야 하는 함수인 콜백에서 발생한다.\n",
    "\n",
    "파이썬 3은 coroutines를 사용하는 asyncio 모듈을 통해 이러한 종류의 실행을 제공한다.\n",
    "\n",
    "## 선점형 멀티태스킹 VS 협력형 멀티태스킹\n",
    "\n",
    "앞서 멀티스레드를 사용해 작성한 프로그램은 동시성 예제였다. 운영체제가 스레드를 실행하는 방법과 시기를 걱정할 필요가 없었다. 스레드를 준비하고 대상 기능을 제공하고 실행했다. 스케줄링은 운영체제가 처리했다.\n",
    "\n",
    "운영체제는 CPU 클럭의 모든 틱마다 실행 중인 스레드를 선점하고 특정 코어에서 다른 스레드로 교체한다. 이것은 여러가지 이유로 발생할 수 있지만 프로그래머는 세부사항을 걱정할 필요가 없다. 스레드를 생성하고 처리해야 하는 데이터와 함께 스레드를 설정하고 올바른 동기화 요소를 사용해 스레드를 시작하면 된다. 운영체제가 스위칭과 스케줄링을 포함한 나머지 작업을 수행한다.\n",
    "\n",
    "이것이 현대 운영체제가 동작하는 방법이며 각 스레드가 실행기간을 공평하게 공유하고 다른 모든 사항이 동일해지는 것을 보장한다. 이 방법은 선점형 멀티태스킹으로 알려져 있다.\n",
    "\n",
    "선점형 멀티태스킹에 반대되는 스케줄링 타입이 있다. 협력형 멀티태스킹으로 우선 순위와 경쟁하는 스레드나 프로세스의 실행에 운영체제가 아무런 역할도 하지 않는다. 대신, 프로세스나 스레드는 다른 프로세스나 스레드가 실행되도록 기꺼이 통제권을 양보한다. 또는 스레드는 유휴 상태나 I/O를 기다리는 또 다른 스레드로 교체될 수 있다.\n",
    "\n",
    "협력형 멀티태스킹 기법은 공동 루틴을 사용하는 동시 실행을 위한 비동기 모델에 사용된다. 데이터를 기다리는 동안이나 네트워크에 반환 값을 요청하는 동안, 아직 반환되지 않은 네트워크를 호출을 하는 함수는 다른 기능이나 태스크가 실행되도록 통제권을 양보할 수 있다.\n",
    "\n",
    "asyncio를 사용하는 실제 공동 루틴을 알아보기 전에 파이썬 생성기를 사용하는 자체적인 협력형 멀티태스킹 스케줄러를 작성해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import collections\n",
    "import threading\n",
    "\n",
    "def number_generator(n):\n",
    "    \"\"\" A co-routine that generates numbers in range 1... n \"\"\"\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        yield i\n",
    "\n",
    "def square_mapper(numbers):\n",
    "    \"\"\" A co-routine task for converting numbers to squares \"\"\"\n",
    "    \n",
    "    for n in numbers:\n",
    "        yield n*n\n",
    "    \n",
    "def prime_filter(numbers):\n",
    "    \"\"\" A co-routine which yields prime numbers \"\"\"\n",
    "    \n",
    "    primes = []\n",
    "    for n in numbers:\n",
    "        if n % 2 == 0: continue\n",
    "        flag = True\n",
    "        for i in range(3, int(n**0.5+1), 2):\n",
    "            if n % i == 0:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            yield n\n",
    "\n",
    "def scheduler(tasks, runs=10000):\n",
    "    \"\"\" Basic task scheduler for co-routines \"\"\"\n",
    "    \n",
    "    results = collections.defaultdict(list)\n",
    "    \n",
    "    for i in range(runs):\n",
    "        for t in tasks:\n",
    "            print(\"Switching to task\", t.__name__)\n",
    "            try:\n",
    "                result = t.__next__()\n",
    "                print(\"Result=>\", result)\n",
    "                results[t.__name__].append(result)\n",
    "            except StopIteration:\n",
    "                break\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드를 분석해 보자.\n",
    "\n",
    "* 4개의 함수를 갖고 있다. yield 키워드를 사용해 데이터를 반환하기 때문에 3개의 생성자와 특정 태스크의 세트를 실행하는 스케줄러 함수를 갖고 있다.\n",
    "* square_mapper 함수는 반복되는 정수를 반환하고 멤버의 제곱을 산출하는 반복자를 받아들인다.\n",
    "* prime_filter 함수는 소수가 아닌 숫자를 필터링하고 소수만 생성하는 유사 반복자를 허용한다.\n",
    "* number_generator 함수는 앞의 두 함수에 대한 입력 반복자로 동작하며, 정수의 입력 스트림을 제공한다.\n",
    "\n",
    "4개의 함수 모두를 묶는 호출 코드를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "tasks = []\n",
    "start = time.clock()\n",
    "limit = int(sys.argv[1])\n",
    "\n",
    "tasks.append(square_mapper(number_generator(limit)))\n",
    "tasks.append(prime_filter(number_generator(limit)))\n",
    "\n",
    "results = scheduler(task, runs=limit)\n",
    "print(\"Last Prime=>\", results['prime_filter'][-1])\n",
    "end.time.clock()\n",
    "print(\"Time taken=>\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 숫자 생성기는 명령행 인자를 통해 받는 카운트를 갖고 초기화된다. 이 값은 square_mapper 함수로 전달된다. 결합된 함수는 tasks 리스트에 태스크로 추가된다.\n",
    "* 유사한 동작이 prime_filter 함수에서도 수행된다.\n",
    "* scheduler 메소드는 각 태스크를 하나씩 실행하는 for 루프를 통해 반복 실행된느 태스크 리스트에 전달돼 실행된다. 결과는 함수 이름을 키로 사용해 딕셔너리에 추가되며 실행이 끝날 때 반환된다.\n",
    "* 실행이 올바른지 검증하기 위해 마짐가 소수값과 스케줄러가 처리를 위해 수행한 시간도 출력한다.\n",
    "\n",
    "10개의 제한 값을 갖는 간단한 협력형 멀티태스킹 스케줄러의 출력을 살펴보자. 다음 화면에서 볼 수 있듯이 단일 명령창에서 모든 입력을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력 결과를 분석해 보자.\n",
    "\n",
    "1. 콘솔에 square_mapper와 prime_filter 함수의 출력이 번갈아 나타나는데 스케줄러가 루프에서 함수 간의 전환 작업을 하기 때문이다. 각 함수는 공통 루틴로 실행을 양보하는데, 제어를 한 함수에서 다른 함수로 전달하며 반대 경우도 마찬가지다. 두 함수를 동시에 실행할 수 있는 반면, 상태를 유지하면서 결과를 생성할 수 있다.\n",
    "\n",
    "2. 여기서는 생성기를 사용했기 때문에 이들은 yield 키워드를 사용해 결과를 생성하고 제어권을 양보하면 더해 결과를 하 번에 생성하는 자연스러운 방법을 제공한다.\n",
    "\n",
    "\n",
    "## 파이썬의 asyncio 모듈\n",
    "\n",
    "파이썬의 asyncio 모듈은 공동 루틴을 사용해 동시성을 갖는 단일 스레드 프로그램의 작성을 지원한다. asyncio 모듈은 파이썬 3에서만 사용이 가능하다.\n",
    "\n",
    "공동 루틴을 사용하는 asyncio 모듈은 다음과 같은 방법 중 하나를 사용한다.\n",
    "\n",
    "* 함수를 정의하기 위해 async def문 사용\n",
    "* @asyncio.coroutine 표현식을 사용한 데코레이션 처리\n",
    "\n",
    "생성기 기반 공동 루틴은 두 번째 방법을 사용하며 이들은 표현식에서 넘겨진다.\n",
    "\n",
    "보통 첫 번째 방법을 사용해 생성된 공동 루틴은 미래에 완료되는 것을 기다리기 위해 await <future> 표현을 사용한다.\n",
    "    \n",
    "공동 루틴은 객체를 연결하고 이들을 태스크로 스케줄링하는 event 루프를 사용해 실행되도록 예약된다. 다양한 운영체제를 위한 여러 타입의 이벤트 루프가 제공된다.\n",
    "\n",
    "다음 코드는 간단한 협력형 멀티태스킹 스케줄러의 이전 예제를 asyncio 모듈을 사용하도록 작성한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "def number_generator(m, n):\n",
    "    yield from range(m, n+1)\n",
    "\n",
    "async def prime_filter(m, n):\n",
    "    primes = []\n",
    "    for i in number_generator(m, n):\n",
    "        if i % 2 == 0: continue\n",
    "        flag = True\n",
    "        \n",
    "        for j in range(3, int(i**0,5+1), 2):\n",
    "            if i % j == 0:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            print(\"Prime=>\", i)\n",
    "            primes.append(i)\n",
    "\n",
    "    await asyncio.sleep(1.0)\n",
    "    return tuple(primes)\n",
    "\n",
    "async def square_mapper(m, n):\n",
    "    squares = []\n",
    "    for i in number_generator(m, n):\n",
    "        print(\"Square => \", i*i)\n",
    "        squares.append(i*i)\n",
    "    \n",
    "    await asyncio.sleep(1.0)\n",
    "    return squares\n",
    "\n",
    "def print_result(future):\n",
    "    print(\"Result =>\", future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 앞의 코드의 동작 방식이다.\n",
    "\n",
    "1. number_generator 함수는 이터레이터인 하위 생성자 range(m, n+1)에서 나오는 공동 루틴이다. 공동 루틴이 다른 공동 루틴을 호출할 수 있게 한다.\n",
    "2. square_mapper 함수는 async def 키워드를 사용하는 첫 번째 타입의 공동 루팁이다. 이 함수는 숫자 생성기에서 숫자들을 사용해 제곱수의 리스트를 반환한다.\n",
    "3. prime_filter 함수 같은 타입이다. 숫자 생성기를 사용하며 리스트에 소수를 추가해 반환한다.\n",
    "4. 두 공동 루틴 모두 asyncio.sleep 함수를 사용하면 휴면 상태를 통해 다른 공동루틴에 실행을 양보하고 대기한다. 두 공동 루틴이 인터리브 방식으로 동시에 동작할 수 있게 한다.\n",
    "\n",
    "다음은 이벤트 루프를 갖는 호출 코드와 나머지 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop = asyncio.get_event_loop()\n",
    "# future = asyncio.gather(prime_filter(10, 50), square_mapper(10, 50))\n",
    "# future.add_done_callback(print_result)\n",
    "# loop.run_until_complete(future)\n",
    "\n",
    "# loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 먼저 asyncio.get_event_loop의 factory 함수를 이용해 asyncio 이벤트 loop를 얻는다. 이것은 운영체제를 위한 기본 이벤트 루프의 구현을 반환한다.\n",
    "\n",
    "2. asyncio 모듈의 gather 메소드를 이용해 asuncio future 객체를 설정한다. gather 메소드는 인수로 전달된 공동 루핀 세트나 futures에서 결과를 집계하는데 사용된다. 우리는 prime_filter와 square_mapper 모두 gather 메소드에 전달한다.\n",
    "\n",
    "3. future 객체에 콜백(print_result 함수)이 추가된다. 콜백은 future의 실행이 끝나면 자동으로 호출된다.\n",
    "\n",
    "4. 루프는 future의 실행이 완료될 때까지 수행된다. future 실행이 끝나는 시점에 콜백이 호출되고 결과가 출력된다. 출력이 인터리브 방식으로 보여지는 것에 주의하자. 각 태스크가 asyncio 모듈의 sleep 함수를 사용해 다른 태스크에 실행권을 넘겨준다.\n",
    "\n",
    "5. 루프가 닫히고 동작이 끝난다.\n",
    "\n",
    "## future의 실행 완료 대기하기 - async와 await\n",
    "\n",
    "await를 사용하는 코루틴 내부에서 미래의 데이터를 기다리는 방법을 알아봤다. 다른 코루틴에는 제어권을 양보하기 위해 await를 사용하는 예제였는데, 이제 웹에서 데이터를 반환하는 미래의 I/O 완료를 기다리는 예제를 살펴보자.\n",
    "\n",
    "예제에서는 asyncio 모듈과 함께 동작하는 HTTP 클라이언트와 서버를 제공하며 futures를 지원하는 aiohttp 모듈이 필요하다. 또한 비동기 코루틴에서 타임아웃을 허용하는 async_timeout 모듈도 필요하다. aiohttp 모듈과 async_yimeout 모듈 모두 pip를 사용해 설치할 수 있다.\n",
    "\n",
    "다음은 이에 대한 코드로 타임아웃을 이용해 URL을 가져오고 future 즉, 동작 결과를 기다린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import async_timeout\n",
    "\n",
    "@asyncio.coroutine\n",
    "def fetch_page(session, url, timeout=60):\n",
    "    with async_timeout.get(url):\n",
    "        response = session.get(url) \n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이벤트 루프가 있는 호출 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop = asyncio.get_event_loop()\n",
    "# urls = (\"http://www.google.com\",\n",
    "#         \"http://www.yahho.com\",\n",
    "#         \"http://www.facebook.com\",\n",
    "#         \"http://www.reddit.com\",\n",
    "#         \"http://www.twitter.com\")\n",
    "# seesion = aiohttp.ClientSession(loop=loop)\n",
    "# tasks = map(lambda x: fetch_page(session, x), urls)\n",
    "# done, pending = loop.run_until_complete(asyncio.wait(tasks, timeout=120))\n",
    "# loop.close()\n",
    "\n",
    "# for future in done:\n",
    "#     response = future.result()\n",
    "#     print(response)\n",
    "#     response.close()\n",
    "#     session.close()\n",
    "# loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이벤트 루와 가져올 URL 리스트를 생성. 또한 URL 패칭을 위한 헬퍼인 aiohttp.ClientSession 객체의 인스턴트 생성\n",
    "2. fetch_page 함수에 각 URL을 매핑해 태스크 맵을 생성. 세션 객체가 fetch_page 함수의 첫 번째 인수로 전달된다.\n",
    "3. 태스크가 120초의 타임아웃을 갖는 asyncio의 wait 메소드에 전달된다.\n",
    "4. 루프가 완료될 때까지 실행되고 두 세트의 futures를 반환한다.\n",
    "5. 완료된 future를 통해 작업을 반복하고 future의 result 메소드를 사용하는 패칭을 통해 응답을 출력한다.\n",
    "\n",
    "실제 응답 텍스트, 콘텐츠 길이, 살태 고드 같은 저 자세한 사항을 얻기 위해 응답을 처리하는 방법\n",
    "\n",
    "다음 함수는 완료된 future의 리스트를 파싱한다. 응답의 read 메소드에 대한 await를 통해 응답 데이터를 기다린다. 각 응답의 데이터를 비동기적으로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_response(futures):\n",
    "    for future in futures:\n",
    "        response = future.result()\n",
    "        data = await response.text()\n",
    "        print(\"Response for URL\", response.url, '=>', response.status, len(data))\n",
    "        response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response 객체의 응답이 마무리되기 전, 해당 메소드에 의해 각 응답의 세부사항인 마지막 URL, 상태 코드, 데이터의 길이가 출력된다.\n",
    "\n",
    "완료된 응답 리스트에 이 작업을 하려면 처리 단계를 하나만 추가하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop.run_until_complete(parse_response(done))\n",
    "# session.close()\n",
    "# loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코루틴 연결하는 방법에 주의해야 한다. 체인의 마지막 링크는 루프가 끝나기 전에 완료된 futures 리스트를 처리하는 parse_response 코루틴이다.\n",
    "\n",
    "## 동시 실행되는 future 객체들 = 고수준의 동시 처리\n",
    "\n",
    "concurrent.futures 모듈은 future 객체를 사용해 데이터를 비동기적으로 반환하는 반면, 스레드나 프로세스를 사용하는 고수준의 동시 처리를 제공한다. \n",
    "concurrent.futures 모듈은 다음과 같은 두 개의 주요 메소드를 갖는 실행 인터페이스를 제공한다.\n",
    "\n",
    "1. submit: 비동기적으로 실행돼야 하는 callable을 제출하고, callable의 실행을 의미하는 future 객체를 반환한다.\n",
    "2. map: iterable의 세트를 callable에 매핑하고, future 객체에서 비동기적으로 실행을 스케줄링한다. 그러나 메소드는 future들의 리스트를 반환하는 대신 처리 결과를 직접 반환한다.\n",
    "\n",
    "실행자 인터페이스를 구현한 방법이 두 가지가 있다. ThreadPoolExecutor는 스레드 풀에서 callable을 실행하고, ProcessPoolExecutor는 프로세스 풀에서 callable을 실행한다.\n",
    "\n",
    "다음은 정수 집합에 대한 팩토리얼을 비동기적으로 계산하는 future 객체의 간단한 예제다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 11 is 39916800\n",
      "Factorial of 10 is 3628800\n",
      "Factorial of 12 is 479001600\n",
      "Factorial of 13 is 6227020800\n",
      "Factorial of 14 is 87178291200\n",
      "Factorial of 15 is 1307674368000\n",
      "Factorial of 16 is 20922789888000\n",
      "Factorial of 17 is 355687428096000\n",
      "Factorial of 18 is 6402373705728000\n",
      "Factorial of 19 is 121645100408832000\n",
      "Factorial of 20 is 2432902008176640000\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "def factorial(n):\n",
    "    return functools.reduce(operator.mul, [i for i in range(1, n+1)])\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    future_map = {executor.submit(factorial, n): n for n in range(10, 21)}\n",
    "    for future in as_completed(future_map):\n",
    "        num =  future_map[future]\n",
    "        print(\"Factorial of\", num, 'is', future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* factorial 함수는 functools.reduce와 곱셈 연산자를 사용해 주어진 숫자에 팩토리얼을 반복적으로 계산한다.\n",
    "* 두 개의 워커를 갖는 실행자를 생성한다. 10부터 20까지 숫자들을 submit 메소드를 통해 제줄한다.\n",
    "* 딕셔너리 내포를 통해 제출이 끝나면 future 키로 숫자 값을 갖는 딕셔너리가 반환된다.\n",
    "* concurrent.futures 모듈의 as_completed 메소드를 사용해, 계산이 완료 처기된 future로 반복 작업을 한다.\n",
    "* 결과는 result 메소드를 통해 future 결과를 가져와 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디스크 썸네일 생성기\n",
    "\n",
    "concurrent.furues 함수를 사용해 썸네일을 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumbnail_image(url, size=(64, 64), format='.png'):\n",
    "    \"\"\" Save thumbnail of an image URL \"\"\"\n",
    "    try:\n",
    "        im = Image.open(urllib.request.urlopen(url))\n",
    "        pieces = url.split('/')\n",
    "        filename = ''.join((pieces[-2],'_',pieces[-1].split('.')[0],'_thumb',format))\n",
    "        im.thumbnail(size, Image.ANTIALIAS)\n",
    "        im.save(filename)\n",
    "        print(\"Saved\", filename)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 처리를 위해 이미지 파일명을 생성하는 반복자라 필요하다. os.walk 함수를 사용해 다음 코드를 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_walker(start_dir):\n",
    "    for root, dirs, files in os.walk(os.path.expanduser(start_dir)):\n",
    "        for f in files:\n",
    "            filename = os.path.join(root, f)\n",
    "            file_type = mimetypes.guess_type(filename.lower())[0]\n",
    "            if file_type != None and file_type.startswith('image/'):\n",
    "                yield filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 함수는 제너레이터다.\n",
    "\n",
    "다음은 실행자를 설정하고 폴더에서 실행하는 호출 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.expanduser('~/Pictures/')\n",
    "if '--process' in sys.argv:\n",
    "    executor = ProcessPoolExecutor(max_workers=10)\n",
    "else:\n",
    "    executor = ThreadPoolExecutor(max_workers=10)\n",
    "with executor:\n",
    "    future_map = {executor.submit(thumbnail_image, filename):\n",
    "    filenmae for filename in directory_walker(root_dir)}\n",
    "    for future in as_completed(future_map):\n",
    "        num = future_map[future]\n",
    "        status = future.result()\n",
    "        if status:\n",
    "            print(\"Thumbnail of \", future_map[future], 'saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 코드는 비동기적으로 함수에 인수를 제출하고 결과 future들을 딕셔너리에 저장하는 동일 기법을 사용한다.\n",
    "루프에서 future가 마무리될 떄 결과를 처리한다.\n",
    "\n",
    "### 동시성 옵션 - 선택 방법\n",
    "\n",
    "스레드, 프로세스, 비동기I/O, 동시성을 갖는 future를 학습했다. 언제 어떤 옵션을 선택할까?\n",
    "\n",
    "결정 사항은 GIL에 영향을 받는 대부분의 경우, 스레드와 프로세스 사이의 선택에서 답은 이미 정했다.\n",
    "동시성 옵션의 선택을 위한 대략적인 가이드라인은 다음과 같다.\n",
    "\n",
    "* 동시성을 갖는 future 대 멀티 프로세싱: 동시성을 갖는 future는 스레드나 프로세스 풀 executore를 사용해 태스크를 병렬화하는 방법을 제공한다. 작업 결과를 바로 사용할 필요가 없을 떄 동시성을 갖는 future는 선택할 수 있다. 동시 실행이 더 복잡하면서 데이터 병렬 처리를 기반으로 하지 않고, 동기화, 공유 메모리를 사용하는 경우는 멀티 프로세싱을 선택할 수 있다. 예를 들어 프로그램이 프로세스, 동기화 기본 요소, IPC가 필요한 경우 실제로 확장할 수 있는 유일한 방법은 멀티 프로세싱 모듈이 제공하는 기본 요소를 사용하는 동시성 프로그램을 작성하는 것이다. 마찬가지로, 멀티스레드를 사용하는 로직이 여러 태스크를 사용하는 데이터의 간단한 병렬 처리를 포함한다면 스레드 풀을 갖는 동시성 future들을 선택할 수 있다. 그러나 복잡한 스레드 도익화 객체로 관리해야 하는 공유 상태가 많다면 스레드 객체를 사용해야 하며 상태를 더 세밀이 제어하기 위해 threading 모듈을 사용하는 멀티스레드로 전환해야 한다.\n",
    "\n",
    "* 비동기 I/O 대 스레드 처리된 동시성: 프로그램이 진정한 동시성을 필요로 하지 않지만 비동기 처리나 콜백에 더 의존적이면 asyncio를 사용해야 한다. asyncio는 사용자 입력 대기, I/O 입력 대기와 같이 애플리케이션이 많은 대기 및 휴면 주기를 포함하고 있는 경우와 코루틴을 통해 다른 태스크를 시작해 대기 시간이나 휴면 시간을 활용해야 할 때 좋다. CPU를 많이 사용하는 동시 처리나 진전한 데이터 병렬 처리를 포함하는 태스크에는 적합하지 않다. asyncio는 많은 I/O가 발생하는 요청 응답 루프에 적합하다. 따라서 실시간 데이터 요구사항이 없는 웹 애플리케이션 서버 작업에 적합하다.\n",
    "\n",
    "### 병렬 처리 라이브러리\n",
    "\n",
    "표준 라이브러리 모듈 이외에도 파이썬은 대칭형 멀티 프로세싱이나 멀티 코어 시스템에서 병렬 처리를 지원하는 풍부한 서드 파티 라이브러리 생태계를 갖추고 있다.\n",
    "\n",
    "### Joblib\n",
    "\n",
    "Joblib은 코드를 루프에서 병렬로 실행하기 위해 멀티 프로세싱에 대한 래퍼를 제공하는 패키지다. 코드는 생성자 표현식으로 작성되며 내부적으로 멀티 프로세싱 모듈을 사용하는 CPU 코어들을 사용해 코드가 병렬로 실행되도록 해석된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def is_prime(n):\n",
    "    for i in range(3, int(n**0.5+1), 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5, 6, 7, 7,8 ,8, 9, 10 ,123, 11, 47, 125, 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=10)(delayed(is_prime)(i) for i in numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMP\n",
    "\n",
    "OpenMP는 개발형 API로 C/C++과 포트란에서 공유 메모리 멀티 프로세싱을 지원한다. 이 라이브러리는 스레드나 프로세스 사이에 작업 분할 방법을 나타내는 pragmas(컴파일러에 관한 특수 명령어)같은 특별한 작업 공유 구조를 사용한다.\n",
    "\n",
    "PyMP는 OpenMP의 기반 아이디어에서 영감을 얻었지만 프로세스의 루프 표현식에서 코드 실행을 병렬화하기 위해 fork 시스템 콜을 사용한다. 이를 위해 PyMP는 리스트 딕셔너리와 같은 공유 데이터 구조와 numpy 배열을 위한 래퍼도 제공한다.\n",
    "\n",
    "코드를 병렬화하기 위해 PyMP의 사용법을 설명하고 성능을 개선하기 위해 프렉탈 예제를 살펴본다.\n",
    "\n",
    "### 프렉탈 - 만델브로트 세트\n",
    "\n",
    "다음은 그래프로 그릴 때 프랙털 기하를 만드는 복잡한 숫자에 관한 클래스의 코드 리스트인 멘델브로트 세트다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from PIL import Image\n",
    "\n",
    "def mandelbrot_calc_row(y, w, h, image, max_iteration = 1000):\n",
    "    \"\"\" Calculate one row of the Mandelbrot set with size wxh \"\"\"\n",
    "    y0 = y * (2/float(h)) - 1\n",
    "    for x in range(w):\n",
    "        x0 = x * (3.5/float(w)) - 2.5\n",
    "        i, z = 0, 0 +0j\n",
    "        c = complex(x0, y0)\n",
    "        while abs(z) < 2 and i < max_iteration:\n",
    "            z = z**2 + c\n",
    "            i += 1\n",
    "        color = (i % 8 * 32, i * 16 * 16, i %32 *8)\n",
    "        image.putpixel((x,y), color)\n",
    "\n",
    "def mandelbrot_calc_set(w, h, max_iteration=10000, output='mandelbrot.png'):\n",
    "    \"\"\" Calculate a mandelbrot set given the width, height and maximum number of iterations \"\"\"\n",
    "    image = Image.new(\"RGB\", (w, h))\n",
    "    \n",
    "    for y in range(h):\n",
    "        mandelbrot_calc_row(y, w, h, image, max_iteration)\n",
    "    image.save(output, \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 코드는 특정 숫자의 c와 가변 지오메트리를 이용해 멘델브로트 세트를 계산한다. 코드는 변화하는 지오메트리의 프렉탈 이미지를 생성하는 인수 파싱으로 끝나며 서로 다른 이터레이션을 지원한다.\n",
    "\n",
    "만델브로트가 일반적으로 생성하는 그림보다 더 아름다운 그림을 생성하기 위해 이 코드는 어느 정도의 자유로움이 필요하며 관련되 프랙털 클래스 즉, 줄리아 세트의 색구성을 사용한다.\n",
    "\n",
    "1. mandelbrot_calc_row 함수는 특정 수의 최대 반복치의 특정 y 좌표 값에 대한 만델브로 집합의 행을 계산한다. x 좌표에 대해 0부터 너비 w까지 전체 행에 대한 픽셀 색상 값이 계산된다. 픽셀 값은 이 함수에 전달된 Image 객체에 넣어진다.\n",
    "    \n",
    "2. mandelbrot_calc_set 함수는 0에서 이미지 높이 h까지 범위의 y 좌표의 모든 값에 mandelbrot_calc_row 함수를 호출한다. 주어진 지어메트리에 대해 Image 객체가 생성되고 픽셀 값으로 채워진다. 마지막으로 이 이미지를 파일에 저장하면 프렉탈을 얻는다.\n",
    "\n",
    "mandelbrot_calc_row 함수를 호출할 때마다 이미지의 한 행이 계산되기 때문에 데이터 병렬 문제에 적합하며 병렬화될 수 있다.\n",
    "\n",
    "### 프렉탈 - 만델브로 셋의 구현 확장\n",
    "루프 외부에서 많은 프로세스를 병렬화하기 위해 PyMP를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "import pymp\n",
    "import argparse\n",
    "\n",
    "def mandelbrot_calc_row(y, w, h, image, max_iteration = 1000):\n",
    "    \"\"\" Calculate one row of the Mandelbrot set with size wxh \"\"\"\n",
    "    y0 = y * (2/float(h)) - 1\n",
    "    for x in range(w):\n",
    "        x0 = x * (3.5/float(w)) - 2.5\n",
    "        i, z = 0, 0 +0j\n",
    "        c = complex(x0, y0)\n",
    "        while abs(z) < 2 and i < max_iteration:\n",
    "            z = z**2 + c\n",
    "            i += 1\n",
    "        color = (i % 8 * 32, i * 16 * 16, i %32 *8)\n",
    "        image_rows[y*w + x] = color\n",
    "\n",
    "def mandelbrot_calc_set(w, h, max_iteration=10000, output='mandelbrot.png'):\n",
    "    \"\"\" Calculate a mandelbrot set given the width, height and maximum number of iterations \"\"\"\n",
    "    image = Image.new(\"RGB\", (w, h))\n",
    "    image_rows = pymp.shared.dict()\n",
    "    with pymp.Parallel(4) as p:\n",
    "        for y in p.range(0, h):\n",
    "            mandelbrot_calc_row(y, w, h, image_rows, max_iteration)\n",
    "    \n",
    "    for i in range(w*h):\n",
    "        x, y = i % w, i // w\n",
    "        image.putpixel((x, y), image_rows[i])\n",
    "    \n",
    "    image.save(output, \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 재작성은 기존 코드에서 만델브로 이미지를 한 줄씩 만드는 코드로 다시 작성하는 것을 포함하며 각 데이터 라인은 개별적으로 계산된다. 이 방식은 개별 프로세스에서 병렬로 계산될 수 있다.\n",
    "\n",
    "1. 단일 프로세스 버전에서는 mandelbrot_calc_row 함수에서 이미지에 픽셀 값을 직접 넣는다. 새로운 코드는 mandelbrot_calc_row 함수를 병렬 프로세스에서 실행하기 때문에, 이미지 데이터를 직접 수정할 수 없다. 대신 새로운 코드가 공유 딕셔너리를 함수에 전달하고, 위치를 key로 사용하며 value를 RGB값으로 사용해 픽셀의 색상 값을 설정한다.\n",
    "\n",
    "2. 결국 새로운 공유 데이터 구조인 공유 딕셔너리는 mandelbrot_calc_set 함수에 추가되고 반복 처리돼 픽셀 데이터가 Image 객체에 채워진다. 그 후, 최종 출력에 저장된다.\n",
    "\n",
    "3. 머신이 4개의 CPU 코어를 갖고 있기 때문에 4개의 PyMP 병렬 프로세스를 사용한다. 이러한 컨텍스트를 사용해 프로세스 내부에서 외부 for 루프를 둘러싼다. 이것은 4개의 코어에서 코드가 병렬로 실행되도록 하며 각 코어는 대략 전체 행의 25%를 계산한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 스케일링 \n",
    "\n",
    "지금까지 알아본 모든 확장성과 동시성 기법들은 단일 서버나 머신 경계 안의 확장성, 다른 말로 스케일링 업을 포함한다. \n",
    "\n",
    "### 워크플로우 확장 - 메시지 큐와 태스크 큐\n",
    "\n",
    "확장성의 중요한 측면 중 하나는 시스템 사이의 결합도를 감소시키는 것이다. 두 시스템이 강하게 결합돼 있으면 시스템은 서로 특정 한계 이상으로 확장하는 것을 방해한다.\n",
    "\n",
    "예를 들어 데이터와 계산이 같은 함수에 함께 있다면 연속적으로 작성된 코드는 프로그램이 여러 CPU 코어 같은 기존 리소스를 활용하지 못하게 만든다. 같은 프로그램을 멀티 스레드와 이들 사이의 큐 같은 메세지 전달 시스템을 사용하도록 다시 작성하면, 프로그램이 여러 CPU로 확장된다는 사실을 확인할 수 있다. 동시성이 이에 해당한다.\n",
    "\n",
    "비슷한 방법으로 웹을 통한 시스템은 분리가 되는 경우는 더 잘 확장된다. 고전적인 예로 클라이언트/서버 아키텍처가 있다. \n",
    "\n",
    "메세지 큐는 애플리케이션들이 서로 메세지를 보내는 분리된 방식으로 통신할 수 있도록 하는 시스템이다. 애플리케이션은 보통 서로 다른 머신이나 인터넷을 통해 연결된 서버에서 실행되며, 큐잉 프로토콜을 통해 통신한다.\n",
    "\n",
    "메세지 큐를 서로 다른 머신의 스레드를 대체하는 멀티스레드 처리된 동기화 큐의 확장 버전인 애플리케이션으로 생각할 수 있으며, 간단한 내부 프로세스 큐를 공유하는 분산 큐로 대체했다고 생각할 수 있다.\n",
    "\n",
    "메세지 큐는 송신 애플리케이션에서 수신 애플리케이션으로 전달되는 메세지인 데이터 패킷을 전달한다. 대부분 메세지 큐는 수신자가 메세지를 처리할 수 있을 떄까지 메세지를 큐에 저장되는 저장하고 전달하는 의미 체계를 제공한다.\n",
    "\n",
    "메세지 큐나 메세지 지향 미들웨어의 가장 인기있고 표준화된 구현된은 AMQP(Advanced Message Queuing Protocol)다. AMQP는 큐잉, 라우팅, 신뢰성 있는 전달, 보안 기능을 제공한다. AMQP는 신뢰성 있고, 안전한 메세지 전달 체계를 매우 중요하게 생각하는 금융업계에서 비롯됐다.\n",
    "\n",
    "AMQP의 구현은 Apache Active MQ, RabbitMP, Apache Qpid다.\n",
    "\n",
    "Rabbit MQ는 얼랭으로 작성된 메세지 지향 미들웨어다. RabbitMQ는 파이썬을 포함한 여러 언어로 라이브러리를 제공한다. 메세지는 항상 라우팅 키를 사용하는 교환키를 통해 전달된다. 교환키는 전달할 메세지의 큐를 의미한다.\n",
    "\n",
    "RabbitMQ와 관련 있지만 약간 다른 관점을 갖는 미들웨어인 셀러리를 알아본다.\n",
    "\n",
    "## 셀러리 - 분산 태스크 큐\n",
    "\n",
    "셀러리는 분산 메세지를 사용해 동작하는 파이썬으로 작성된 분산 태스크 큐다. 셀러리 안에서 각 실행 단위를 태스크라고 한다. 태스크는 워커라고 하는 프로세스를 사용해 하나 이상의 서버에서 동시에 실행될 수 있다. 셀러리는 보통 multi processing 모듈로 작업하지만 gevent 같이 다른 백엔드를 사용할 수도 있다.\n",
    "\n",
    "태스크는 객체 같이 미래에 이용한 결과를 갖고 동기적, 비동기적으로 실행될 수 있다. 또한 태스크의 결과는 Redis, 데이터베이스, 파일 같은 저장소 백엔드에도 저장될 수 있다.\n",
    "\n",
    "셀러리는 기본 단위가 메세지라기보다는 실행 가능한 태스크라는 점에서 메세지 큐와 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샐러리는 메세지큐와 함께 동작하게 만들 수 있다. 실제로 셀러리에서 메세지 전달을 위한 기본 브로커는 AMQP의 인기있는 구현인 RabbitMQ이다. 셀러리는 브로커 백엔드로 Redis와 함꼐 동작할 수 있다.\n",
    "\n",
    "셀러리는 태스크를 수행하고 여러 서버에 있는 여러 워커로 태스크를 확장하기 때문에 컴퓨터를 사용하는 계산의 확장뿐 아니라 데이터 병렬 처리를 포함하는 문제에도 적합하다. 셀러리는 큐로부터 메세지를 수락하고 여러 머신으로 태스크를 분배할 수 있다. 예를 들어 분산 이메일 전달 시스템 구현하고 수평 확장성을 달성할 수 있다. 또한 단일 함수를 수행하고 여러 프로세스로 데이터를 분할해 병렬로 데이터를 처리할 수 있다.\n",
    "\n",
    "다음 예제에서는 멘델브로 프렉탈 프로그램을 사용한다. 샐러리와 함께 동작하도록 이전 프로그램을 다시 작성한다. \n",
    "\n",
    "### 셀러리를 사용하는 멘델로브 세트\n",
    "\n",
    "셀러리를 활용하는 프로그램을 구현하려면 프로그램을 태스크로 만들어야 하는데 그리 어렵지 않다. 선택된 브로커 백엔드를 사용해 샐러리 애플리케이션의 인스턴스를 준비하고 병렬로 처리하고픈 callable을 데코레이션으로 처리하면 된다. \n",
    "\n",
    "프로그램에 몇 가지 새로운 사항이 있으므로 프로그램을 단계별로 살펴본다. 소프트웨어 요구사항은 다음과 같다.\n",
    "\n",
    "* 셀러리\n",
    "* AMQP 백엔드: RabbitMQ\n",
    "* 결과를 저장하는 백엔드로 Redis 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "\n",
    "app = Celery('task', broker='pyamqp://quest@localhost', backend='redis://localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.task\n",
    "def mandelbrot_calc_row(y, w, h, max_iteration = 1000):\n",
    "    y0 = y * (2/float(h)) - 1\n",
    "\n",
    "    image_rows = {}\n",
    "    for x in range(w):\n",
    "        x0 = x * (3.5/float(w)) - 2.5\n",
    "        i, z = 0, 0 +0j\n",
    "        c = complex(x0, y0)\n",
    "        while abs(z) < 2 and i < max_iteration:\n",
    "            z = z**2 + c\n",
    "            i += 1\n",
    "        color = (i % 8 * 32, i * 16 * 16, i %32 *8)\n",
    "        image_rows[y*w + x] = color\n",
    "    return image_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 셀러리에 필요한 import 수행. \n",
    "* 메세지 브로커로 AMQP, 결과 백엔드로 Redis를 사용하는 샐러리 애플리케이션으로 Celery 클래스의 인스턴스를 준비한다.\n",
    "* mandelbrot_calc_row 수정 버전을 갖고 있다.\n",
    "* 애플리케이션이 셀러리 인스턴스이므로 @app.task를 사용해 함수를 데코레이션 처리했다.\n",
    "\n",
    "y 입력 값의 범위에 대해 태스크를 호출하고 이미지를 생성하는 메인 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from celery import group\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandelbrot_main(w, h, max_iteration=1000, output='madel_celery.png'):\n",
    "    # Main function for mandelbrot program with celery\n",
    "    \n",
    "    # Create a job - a group of tasks\n",
    "    job = group([mandelbrot_calc_row.s(y, w, h, max_iteration) for y in range(h)])\n",
    "    # Call it asynchrously\n",
    "    result = job.apply_async()\n",
    "    image = Image.new(\"RGB\", (w, h))\n",
    "    for image_rows in result.join():\n",
    "        for k, v in image_rows.items():\n",
    "            k = int(k)\n",
    "            v = tuple(map(int, v))\n",
    "            x, y = k % args.width, k // args.width\n",
    "            image.putpixel((x,y), v)\n",
    "    image.save(output, 'PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬으로 웹 서비스하기 - WSGI\n",
    "\n",
    "WSGI는 서버 측면과 애플리케이션을 개발하기 위해 서버와 웹 애플리케이션 프레임워크 사이의 간단하지만 같은 인터페이스를 지정한다.\n",
    "\n",
    "* 서버 측은 애플리케이션을 실행하고 환경과 콜백 함수를 함께 제공한다.\n",
    "* 애플리케이션은 요청을 처리하고 제공된 콜백 함수를 이용해 서버에 응답을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSGI의 애플리케이션이나 프레임워크 측면에 호환되는 간단한 함수.\n",
    "def simple_app(environ, start_respone):\n",
    "    status = '200 OK'\n",
    "    response_header = [('Content-type', 'text/plain')]\n",
    "    start_response(status, response_header)\n",
    "    return ['Hello world!\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. environ 변수는 CGI 명세에 정의된 서버에서 전달받은 애플리케이션의 환경 변수에 관한 딕셔너리다. WSGI는 이러한 환경 변수의 일부를 해당 사양에서 필수로 만든다.\n",
    "\n",
    "2. start_response는 서버에서 애플리케이션으로 응답 처리를 시작하기 위해 콜백으로 제공된 callable이다. 이것은 두 개의 위치 인수를 가져야 한다. 첫 번째는 정수 상태의 코드를 갖는 상태 문자열이먀, 두 번째는 HTTP 응답 헤더를 설명하는, 튜플의 리스트여야 한다.\n",
    "\n",
    "WSGI 미들웨어 컴포넌트는 두 측면 모두에서 명세를 구현하는 소프트웨어다. 다음 기능을 제공한다.\n",
    "\n",
    "* 서버에서 애플리케이션으로 하는 여러 요청의 로드 밸런싱\n",
    "* 네트워크를 통한 요청과 응답의 전달을 통한 요청의 원격처리\n",
    "* 같은 프로세스 안의 멀티테넌시나 여러 서버 또는 애플리케이션의 공동 호스팅\n",
    "* 다양한 애플리케이션 객체에 대한 요청의 URL 기반 라우팅\n",
    "\n",
    "미들웨어는 서버와 애플리케이션 사이에 위치한다. 서버의 요청을 애플리케이션으로 전달하고 응답을 애플리케이션에서 서버로 전달한다.\n",
    "\n",
    "아키텍트가 선택할 수 있는 많은 WSGI 미들웨어가 있다. 가장 인기 있는 두 미들웨어인 uWSGI와 Gunicorn를 간단히 살펴본다.\n",
    "\n",
    "### uWSGI - 강력한 WSGI 미들웨어\n",
    "\n",
    "uWSGI는 호스팅 서비스를 위한 전체 스택 구축을 목표로 하는 오픈소스 프로젝트이자 애플리케이션이다. uWSGI 프로젝트의 WSGI 프로젝트는 파이썬용 WSGI 인터페이스 플러그인으로, Uwsgi 프로젝트에서 개발된 첫 번째 플러그인이다.\n",
    "\n",
    "uWSGI의 컴포넌트는 미리 포크되고 스레드 처리된, 비동기 그린 스레드/공동 루틴 모드에서 실행될 수 있다.\n",
    "\n",
    "uWSGI는 웹 애플리케이션의 응답을 uWSGI 서버상의 여러 캐시에 저장할 수 있는 빠른 인메모리 캐싱 프레임워크를 제공한다. 캐시는 파일 같은 영구적인 저장소에 백업될 수 있다. uWSGI는 파이썬에서 virtualenv 기반의 배포도 지원한다.\n",
    "\n",
    "uWSGI는 uWSGI 서버에서 사용되는 네이티브 프로토콜도 제공한다. \n",
    "\n",
    "uWSGI는 높은 성능과 기능의 적절한 균형이 필요할 때 파이썬 웹 애플리케이션 프로덕션 배포를 위한 이상적인 선택이다. uWSGI는 WSGI 웹 애플리케이션 배포를 위한 다목적 맥가이버 칼 같은 컴포넌트다. \n",
    "\n",
    "### Gunicorn - WSGI용 유니콘\n",
    "\n",
    "Gunicorn 프로젝트는 인기있는 WSGI 미들웨어 구현이자 오픈소스다. Gunicorn 프리포크 모델을 사용하며 루비의 unicorn 프로젝트의 이식 버전이다. Gunicorn에는 다양한 타입의 워커들이 있다. 비동기 워커는 gevent의 상단에 구축된 Grennlet fkdlqmfjflfmf tkdydgksek.\n",
    "\n",
    "Gunicorn에는 이벤트 루프를 실행하고 다양한 신호를 처리하고 반응하는 마스터 프로세스가 있다. 마스터는 워크를 관리하고 워커 프로세스는 요청의 처리와 응답을 전송한다.\n",
    "\n",
    "### Gunicorn VS uWSGI\n",
    "\n",
    "* 많은 커스터마이즈가 필요 없는 간단한 애플리케이션을 배포할 때 Gunicorn은 좋은 선택지다. uWSGI는 러닝 커브가 Gunicorn보다 크다. Gunicorn은 대부분의 배포에 잘 작동한다.\n",
    "\n",
    "* 배포가 파이썬 한 가지라면 Gunicorn은 좋은 대안이다. uWSGI는 PSGI와 Rack 같은 다른 스택을 지원하기 때문에 이기종 배포를 수행할 수 있다.\n",
    "\n",
    "* 더 많이 커스터마이징할 수 있는 기능이 있는 WSGI 미들웨어를 원한다면 uWSGI가 안전한 선택이다. 예를 들어 uWSGI는 파이썬 virtualenv 기반 배포를 간단하게 만든다. Gunicorn은 virtualenv를 지원하지 않는다 Gunicorn는 자체 가상 환경으로 배포해야 한다.\n",
    "\n",
    "* NginX는 uWSGI를 기본으로 지원하기 떄문에 대부분 프로덕션 시스템에 NginX와 함꼐 배포된다. NginX를 사용하고 완전한 기능의 많은 커스터마이징을 할 수 있는 캐싱 기능이 있는 WSGI 미들웨어를 찾을 떄는 uWSGI가 기본적인 선택이다.\n",
    "\n",
    "* 성능과 관련해 Gunicorn과 uWSGI 모두 웹상에 게시된 다양한 벤치마크에서 비슷한 점수를 받고 있다.\n",
    "\n",
    "### 확장 아키텍처 \n",
    "\n",
    "#### 수직적 확장 아키텍처\n",
    "\n",
    "* 기존 시스템에 더 많은 리소스를 추가한다. \n",
    "\n",
    "* 시스템의 기존 자원을 더 잘 활용한다.\n",
    "\n",
    "#### 수평적 확장 아키텍처\n",
    "\n",
    "* 능동적인 중복: 스케일 아웃의 가장 간단한 기법으로 앞 단에 로드밸런서를 갖는 여러 개의 같은 처리 노드의 추가를 포함한다. \n",
    "\n",
    "* 상시 대시 서버: 치명적인 실패가 발생하면 로드 밸런서는 상시 대기 서버로 전환되도록 구성된다.\n",
    "\n",
    "* 읽기 복제본: 많은 읽기 작업에 의존하는 시스템의 응답은 데이터베이스에 읽기 전용 복제본을 추가해 향상시킬 수 있다. 읽기 복제본은 핫 백업을 제공하는 데이터베이스 노드로 메인 데이터베이스 노드와 계속해 동기화된다. 주어진 시점의 일기 복제본은 메인 데이터베이스 노드와 정확하게 일치하지 않을 수도 있다.\n",
    "\n",
    "* 블루-그린 배포: blue와 green으로 표시되는 두 개의 분리된 시스템을 나란히 실행하는 기법이다. 주어진 임의의 시간에 오직 하나의 시스템만 액티브 상태로 요청을 처리한다. 새로운 배포를 준빌할 때 유휴 시스템으로 배포를 수행한다. 유휴 시스템이 활성 시스템이 되고 블루는 유휴 상태가 된다. 블루 그린 배포가 올바르게 수행된다면 프로덕션 애플리케이션의 중단 시간은 없거나 최소 시간을 보장한다.\n",
    "\n",
    "* 장애 모니터링 및 재시작: 실패 모니터는 배포에 있어 중용한 컴포넌트의 실패를 감지하고 통지하거나 중단 시간을 감소시키는 조치를 하는 시스템이다. 가령 서버에 중요한 컴포넌트 즉, 셀러리나 rabbitmq 서버가 다운된 것을 감지하면 데브옵스 담당자에게 이메일을 보내고 데몬의 재시작을 시도하는 모니터링 애플리케이션을 설치할 수 있다. 하트비트 모니터링은 소프트웨어가 같은 머신이나 다른 서버에 있는 모니터링 소프트웨어나 하드웨어로 능동적으로 핑을 하거나 하트비트를 보내는 기법이다. \n",
    "\n",
    "* 캐시를 사용하라: 시스템에 가능한 많은 캐시를 사용하고, 할 수 있다면 분산 캐시를 사용하라. 다양한 캐시 타입을 사용할 수 있는데 가장 간단하고 적용 가능한 캐시는 애플리케이션 서비스 공급자의 CDN에 정적 리소스를 캐싱하는 것이다. 두 번째 종류의 캐시는 응답과 데이터베이스 쿼리 결과를 캐시하는 애플리케이션 캐시다. 이때는 대부분 Memcached와 Redis가 사용된다. 그리고 이들은 일반적으로 마스터/슬레이브 모드에서 분산 배포를 제공한다. 이러한 캐시는 데이터가 너무 오래 보관되지 않도록 적절한 만료 시간을 설정해 애플리케이션에서 가장 일반적으로 요청되는 컨텐츠를 로드하고 캐시할 때 사용돼야 한다. \n",
    "\n",
    "* 분리: 네트워크의 공유된 부분을 가능한 많이 활용하기 위해 컴포넌트를 분리한다. 예르 들어 메세지 큐는 동일 머신에서 로컬 데이터베이스나 소켓을 사용하는 대신, 데이터를 게시하고 구독하기 위해 애플리케이션에서 컴포넌트를 분리하는 데 사용될 수 있다. 분리하기 위해 추가하는 새로운 컴포넌트는 자체 상태를 갖는 스토리지와 클러스터링 기능을 함꼐 제공하기 때문에 컴포넌트를 분리하면 자동으로 세스템에 중복성과 데이터 백업이 도입된다.\n",
    "\n",
    "* 우아한 감소: 요청에 응답하고 타임아웃을 제공하지 못하는 것보다 시스템이 우아하게 저하된 동작을 하도록 해야 한다. 쓰기가 많은 웹  애플리케이션은 과도한 부하 아래서 데이터베이스 노드가 응답하지 않을 때 읽기 전용 모드로 전환할 수 있다. 우아한 감소는 애플리케이션 자체 구성이나 로드 밸런서, 두 가지 모두에 의해 구성할 수 있다.\n",
    "\n",
    "* 데이터를 코드와 밀접하게 유지한다: 성능이 우수한 소프트웨어의 황금률은 계산이 되는 곳에 데이터를 제공하는 것이다. 예를 들어 애플리케이션이 모든 요청에 원격 데이터베이스로부터 데이터를 로드하기 위해 50개의 SQL 쿼리를 만드는 것은 호아금률을 제대로 지킨 것이 아니다. 계산 위치에 가까운 곳에서 데이터를 제공하면 데이터를 제공하면 데이터 액세스 및 전ㄴ송 시간이 감소된다. 이것은 처리시간, 즉 애플리케이션의 지연 시간을 감소시키고 시스템을 더욱 더 확장 가능하게 만든다. 이를 위해 캐싱이 가장 선호되는 기법이다. 다른 기법은 데이터베이스를 로컹 데이터베이스와 원격 데이터베이스로 나누는 것이다. \n",
    "\n",
    "* SLA에 따른 설계: 애플리케이션이 사용자에게 제공하는 보증 항목을 아키텍트가 이해하고, 이에 따라 배포 아키텍쳐를 이해해야 한다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
